{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost nfl_data_py pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2522d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFL Game Prediction using nfl_data_py\n",
    "# Updated version of NFL prediction pipeline using modern, maintained data source\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot  \n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.calibration import CalibratedClassifierCV as CCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Advanced ML libraries\n",
    "try: \n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "\n",
    "# NFL data library\n",
    "try:\n",
    "    import nfl_data_py as nfl\n",
    "    HAS_NFL_DATA = True\n",
    "except ImportError:\n",
    "    HAS_NFL_DATA = False\n",
    "    print(\"nfl_data_py not available. Install with: pip install nfl_data_py\")\n",
    "\n",
    "class NFLGamePredictor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.best_features = []\n",
    "        self.scaler = StandardScaler()\n",
    "        self.final_model = None\n",
    "        \n",
    "    def collect_data(self, start_year=2010, end_year=2024, save_csv=True, data_folder='nfl_data'):\n",
    "        \"\"\"Collect comprehensive NFL data using nfl_data_py and save as CSV files\"\"\"\n",
    "        \n",
    "        if not HAS_NFL_DATA:\n",
    "            raise ImportError(\"nfl_data_py is required. Install with: pip install nfl_data_py\")\n",
    "        \n",
    "        print(f\"Collecting NFL data from {start_year} to {end_year}...\")\n",
    "        \n",
    "        # Create data folder if it doesn't exist\n",
    "        if save_csv and not os.path.exists(data_folder):\n",
    "            os.makedirs(data_folder)\n",
    "            print(f\"Created data folder: {data_folder}\")\n",
    "        \n",
    "        years = list(range(start_year, end_year + 1))\n",
    "        \n",
    "        # Get play-by-play data for game-level statistics\n",
    "        print(\"Downloading play-by-play data...\")\n",
    "        try:\n",
    "            pbp_data = nfl.import_pbp_data(years)\n",
    "            print(f\"✓ Play-by-play data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading play-by-play data: {e}\")\n",
    "            # Try with reduced year range\n",
    "            years = list(range(start_year, 2024 + 1))\n",
    "            pbp_data = nfl.import_pbp_data(years)\n",
    "            print(f\"✓ Play-by-play data downloaded (adjusted to {start_year}-2024)\")\n",
    "        \n",
    "        # Get team information\n",
    "        print(\"Downloading team information...\")\n",
    "        teams = nfl.import_team_desc()\n",
    "        team_dict = teams.set_index('team_abbr')['team_name'].to_dict()\n",
    "        \n",
    "        # Get weekly data for season-long team statistics\n",
    "        print(\"Downloading weekly team data...\")\n",
    "        try:\n",
    "            weekly_data = nfl.import_weekly_data(years)\n",
    "            print(f\"✓ Weekly data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading weekly data: {e}\")\n",
    "            print(\"Trying with 2015-2024 data only...\")\n",
    "            # Fall back to confirmed available years\n",
    "            years_safe = list(range(2015, 2024 + 1))\n",
    "            weekly_data = nfl.import_weekly_data(years_safe)\n",
    "            print(f\"✓ Weekly data downloaded (2015-2024)\")\n",
    "        \n",
    "        # Get schedule data\n",
    "        print(\"Downloading schedule data...\")\n",
    "        try:\n",
    "            schedule_data = nfl.import_schedules(years)\n",
    "            print(f\"✓ Schedule data downloaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading schedule data: {e}\")\n",
    "            print(\"Trying with 2015-2024 data only...\")\n",
    "            # Fall back to confirmed available years\n",
    "            years_safe = list(range(2015, 2024 + 1))\n",
    "            schedule_data = nfl.import_schedules(years_safe)\n",
    "            print(f\"✓ Schedule data downloaded (2015-2024)\")\n",
    "        \n",
    "        # Try to get 2025 Week 1 data separately if available\n",
    "        print(\"Attempting to download 2025 Week 1 data...\")\n",
    "        try:\n",
    "            pbp_2025 = nfl.import_pbp_data([2025])\n",
    "            if not pbp_2025.empty:\n",
    "                pbp_data = pd.concat([pbp_data, pbp_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 play-by-play data added\")\n",
    "            \n",
    "            weekly_2025 = nfl.import_weekly_data([2025])\n",
    "            if not weekly_2025.empty:\n",
    "                weekly_data = pd.concat([weekly_data, weekly_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 weekly data added\")\n",
    "                \n",
    "            schedule_2025 = nfl.import_schedules([2025])\n",
    "            if not schedule_2025.empty:\n",
    "                schedule_data = pd.concat([schedule_data, schedule_2025], ignore_index=True)\n",
    "                print(\"✓ 2025 schedule data added\")\n",
    "        except Exception as e:\n",
    "            print(f\"2025 data not available yet: {e}\")\n",
    "            print(\"Proceeding with 2015-2024 data only\")\n",
    "        \n",
    "        print(f\"Collected {len(pbp_data)} play-by-play records\")\n",
    "        print(f\"Collected {len(weekly_data)} weekly team records\") \n",
    "        print(f\"Collected {len(schedule_data)} scheduled games\")\n",
    "        \n",
    "        # Save data as CSV files if requested\n",
    "        if save_csv:\n",
    "            print(f\"\\nSaving data to CSV files in '{data_folder}' folder...\")\n",
    "            \n",
    "            # Save play-by-play data (this will be large)\n",
    "            pbp_file = os.path.join(data_folder, f'pbp_data_{start_year}_{end_year}.csv')\n",
    "            pbp_data.to_csv(pbp_file, index=False)\n",
    "            print(f\"✓ Saved play-by-play data: {pbp_file} ({len(pbp_data):,} rows)\")\n",
    "            \n",
    "            # Save weekly data\n",
    "            weekly_file = os.path.join(data_folder, f'weekly_data_{start_year}_{end_year}.csv')\n",
    "            weekly_data.to_csv(weekly_file, index=False)\n",
    "            print(f\"✓ Saved weekly data: {weekly_file} ({len(weekly_data):,} rows)\")\n",
    "            \n",
    "            # Save schedule data\n",
    "            schedule_file = os.path.join(data_folder, f'schedule_data_{start_year}_{end_year}.csv')\n",
    "            schedule_data.to_csv(schedule_file, index=False)\n",
    "            print(f\"✓ Saved schedule data: {schedule_file} ({len(schedule_data):,} rows)\")\n",
    "            \n",
    "            # Save team information\n",
    "            teams_file = os.path.join(data_folder, 'team_info.csv')\n",
    "            teams.to_csv(teams_file, index=False)\n",
    "            print(f\"✓ Saved team info: {teams_file} ({len(teams):,} rows)\")\n",
    "            \n",
    "            # Save a sample of each dataset for quick inspection\n",
    "            print(f\"\\nSaving sample data for quick inspection...\")\n",
    "            \n",
    "            # Sample play-by-play (first 1000 rows)\n",
    "            pbp_sample_file = os.path.join(data_folder, 'pbp_sample.csv')\n",
    "            pbp_data.head(1000).to_csv(pbp_sample_file, index=False)\n",
    "            print(f\"✓ Saved PBP sample: {pbp_sample_file} (1,000 rows)\")\n",
    "            \n",
    "            # Sample weekly data (recent season)\n",
    "            weekly_sample = weekly_data[weekly_data['season'] >= end_year - 1]\n",
    "            weekly_sample_file = os.path.join(data_folder, 'weekly_sample.csv')\n",
    "            weekly_sample.to_csv(weekly_sample_file, index=False)\n",
    "            print(f\"✓ Saved weekly sample: {weekly_sample_file} ({len(weekly_sample):,} rows from {end_year-1}-{end_year})\")\n",
    "            \n",
    "            # Show column information\n",
    "            print(f\"\\nDATA STRUCTURE OVERVIEW:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Play-by-Play Columns ({len(pbp_data.columns)}): {list(pbp_data.columns[:10])}...\")\n",
    "            print(f\"Weekly Data Columns ({len(weekly_data.columns)}): {list(weekly_data.columns)}\")\n",
    "            print(f\"Schedule Columns ({len(schedule_data.columns)}): {list(schedule_data.columns)}\")\n",
    "            print(f\"Team Info Columns ({len(teams.columns)}): {list(teams.columns)}\")\n",
    "            \n",
    "            print(f\"\\nDATA SAVED SUCCESSFULLY!\")\n",
    "            print(f\"Check the '{data_folder}' folder to examine the downloaded data.\")\n",
    "        \n",
    "        return pbp_data, weekly_data, schedule_data, team_dict\n",
    "    \n",
    "    def _calculate_injury_percentage(self, team_data):\n",
    "        \"\"\"\n",
    "        Calculate estimated injury percentage based on available performance metrics\n",
    "        \n",
    "        This method estimates team injury impact by analyzing performance consistency\n",
    "        and key player availability indicators in the data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # If we have specific injury data columns, use them\n",
    "        if 'injuries' in team_data.columns:\n",
    "            return team_data['injuries'].mean()\n",
    "        \n",
    "        # Estimate injury impact based on performance variance and available metrics\n",
    "        # Higher variance in key stats might indicate injury-related inconsistency\n",
    "        \n",
    "        injury_indicators = []\n",
    "        \n",
    "        # 1. Passing performance consistency (QB health indicator)\n",
    "        if 'passing_yards' in team_data.columns and len(team_data) > 1:\n",
    "            passing_std = team_data['passing_yards'].std()\n",
    "            passing_mean = team_data['passing_yards'].mean()\n",
    "            if passing_mean > 0:\n",
    "                passing_variance = (passing_std / passing_mean) * 100\n",
    "                injury_indicators.append(min(passing_variance, 30))  # Cap at 30%\n",
    "        \n",
    "        # 2. Rushing performance consistency (RB/OL health indicator)\n",
    "        if 'rushing_yards' in team_data.columns and len(team_data) > 1:\n",
    "            rushing_std = team_data['rushing_yards'].std()\n",
    "            rushing_mean = team_data['rushing_yards'].mean()\n",
    "            if rushing_mean > 0:\n",
    "                rushing_variance = (rushing_std / rushing_mean) * 100\n",
    "                injury_indicators.append(min(rushing_variance, 25))  # Cap at 25%\n",
    "        \n",
    "        # 3. Completion percentage consistency (QB/WR health indicator)\n",
    "        if 'completions' in team_data.columns and 'passing_attempts' in team_data.columns:\n",
    "            comp_pct = team_data['completions'] / (team_data['passing_attempts'] + 0.1)  # Avoid division by zero\n",
    "            if len(comp_pct) > 1:\n",
    "                comp_std = comp_pct.std()\n",
    "                comp_variance = comp_std * 100\n",
    "                injury_indicators.append(min(comp_variance, 20))  # Cap at 20%\n",
    "        \n",
    "        # 4. Fantasy points consistency (overall team health)\n",
    "        if 'fantasy_points' in team_data.columns and len(team_data) > 1:\n",
    "            fp_std = team_data['fantasy_points'].std()\n",
    "            fp_mean = team_data['fantasy_points'].mean()\n",
    "            if fp_mean > 0:\n",
    "                fp_variance = (fp_std / fp_mean) * 100\n",
    "                injury_indicators.append(min(fp_variance, 35))  # Cap at 35%\n",
    "        \n",
    "        # Calculate weighted average injury percentage\n",
    "        if injury_indicators:\n",
    "            # Weight more recent games higher (if we have game order info)\n",
    "            weights = [1.0] * len(injury_indicators)  \n",
    "            weighted_avg = sum(i * w for i, w in zip(injury_indicators, weights)) / sum(weights)\n",
    "            \n",
    "            # Normalize to 0-100% range and apply league baseline\n",
    "            # NFL teams typically have 10-25% of roster dealing with some injury\n",
    "            baseline_injury_rate = 15.0  # League average baseline\n",
    "            estimated_injury_pct = min(max(weighted_avg, 5.0), 40.0)  # 5-40% range\n",
    "            \n",
    "            # Blend with baseline for more realistic estimates\n",
    "            final_injury_pct = (estimated_injury_pct * 0.7) + (baseline_injury_rate * 0.3)\n",
    "            \n",
    "            return final_injury_pct\n",
    "        \n",
    "        # Default injury rate if no data available\n",
    "        return 15.0  # NFL league average\n",
    "    \n",
    "    def _calculate_defensive_stats(self, weekly_data, schedule_data, season, week):\n",
    "        \"\"\"\n",
    "        Calculate defensive statistics (yards/points allowed) for each team.\n",
    "        OPTIMIZED VERSION - Pre-aggregate weekly data for faster lookups.\n",
    "        \"\"\"\n",
    "        defensive_stats = {}\n",
    "        \n",
    "        # Filter to relevant season/weeks\n",
    "        season_schedule = schedule_data[\n",
    "            (schedule_data['season'] == season) & \n",
    "            (schedule_data['week'] < week)\n",
    "        ].copy()\n",
    "        \n",
    "        if season_schedule.empty:\n",
    "            return {}\n",
    "        \n",
    "        # PRE-AGGREGATE: Create team totals per week (MUCH FASTER)\n",
    "        season_weekly = weekly_data[\n",
    "            (weekly_data['season'] == season) & \n",
    "            (weekly_data['week'] < week)\n",
    "        ]\n",
    "        \n",
    "        if season_weekly.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Group by team and week, sum all player stats\n",
    "        team_week_totals = season_weekly.groupby(['recent_team', 'week']).agg({\n",
    "            'passing_yards': 'sum',\n",
    "            'rushing_yards': 'sum'\n",
    "        }).reset_index()\n",
    "        team_week_totals['total_yards'] = team_week_totals['passing_yards'] + team_week_totals['rushing_yards']\n",
    "        \n",
    "        # CRITICAL OPTIMIZATION: Create lookup dictionary for O(1) access instead of repeated filtering\n",
    "        yards_lookup = {}\n",
    "        for _, row in team_week_totals.iterrows():\n",
    "            key = (row['recent_team'], row['week'])\n",
    "            yards_lookup[key] = row['total_yards']\n",
    "        \n",
    "        # Get all unique teams from schedule (vectorized)\n",
    "        all_teams = set(pd.concat([\n",
    "            season_schedule['home_team'].dropna(),\n",
    "            season_schedule['away_team'].dropna()\n",
    "        ]).unique())\n",
    "        \n",
    "        for team in all_teams:\n",
    "            # Get all games for this team (one filter operation)\n",
    "            team_home = season_schedule[season_schedule['home_team'] == team]\n",
    "            team_away = season_schedule[season_schedule['away_team'] == team]\n",
    "            \n",
    "            total_yards_allowed = 0\n",
    "            total_points_allowed = 0\n",
    "            games_count = 0\n",
    "            \n",
    "            # Process home games (defending against away team)\n",
    "            for _, game in team_home.iterrows():\n",
    "                if pd.notna(game.get('away_score')):\n",
    "                    opponent = game['away_team']\n",
    "                    game_week = game['week']\n",
    "                    points_allowed = game['away_score']\n",
    "                    \n",
    "                    # O(1) dictionary lookup instead of DataFrame filter\n",
    "                    yards_allowed = yards_lookup.get((opponent, game_week), 0)\n",
    "                    if yards_allowed > 0:\n",
    "                        total_yards_allowed += yards_allowed\n",
    "                        total_points_allowed += points_allowed\n",
    "                        games_count += 1\n",
    "            \n",
    "            # Process away games (defending against home team)\n",
    "            for _, game in team_away.iterrows():\n",
    "                if pd.notna(game.get('home_score')):\n",
    "                    opponent = game['home_team']\n",
    "                    game_week = game['week']\n",
    "                    points_allowed = game['home_score']\n",
    "                    \n",
    "                    # O(1) dictionary lookup\n",
    "                    yards_allowed = yards_lookup.get((opponent, game_week), 0)\n",
    "                    if yards_allowed > 0:\n",
    "                        total_yards_allowed += yards_allowed\n",
    "                        total_points_allowed += points_allowed\n",
    "                        games_count += 1\n",
    "            \n",
    "            # Calculate per-game averages\n",
    "            if games_count > 0:\n",
    "                defensive_stats[team] = {\n",
    "                    'def_yards_allowed_pg': total_yards_allowed / games_count,\n",
    "                    'def_points_allowed_pg': total_points_allowed / games_count\n",
    "                }\n",
    "            else:\n",
    "                defensive_stats[team] = {\n",
    "                    'def_yards_allowed_pg': 0,\n",
    "                    'def_points_allowed_pg': 0\n",
    "                }\n",
    "        \n",
    "        return defensive_stats\n",
    "    \n",
    "    def create_team_features(self, weekly_data, season, week, schedule_data=None):\n",
    "        \"\"\"\n",
    "        Create team-level features for a specific season/week.\n",
    "        \n",
    "        CRITICAL: weekly_data contains PLAYER-level statistics.\n",
    "        We must aggregate multiple players per team per week to get team totals.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter data up to the current week\n",
    "        season_data = weekly_data[\n",
    "            (weekly_data['season'] == season) & \n",
    "            (weekly_data['week'] < week)\n",
    "        ]\n",
    "        \n",
    "        if season_data.empty:\n",
    "            return {}\n",
    "        \n",
    "        # Check if 'recent_team' column exists\n",
    "        if 'recent_team' not in season_data.columns:\n",
    "            print(\"Warning: 'recent_team' column not found in weekly_data\")\n",
    "            return {}\n",
    "        \n",
    "        # Calculate defensive stats if schedule data provided\n",
    "        defensive_stats = {}\n",
    "        if schedule_data is not None:\n",
    "            defensive_stats = self._calculate_defensive_stats(weekly_data, schedule_data, season, week)\n",
    "        \n",
    "        # Calculate season averages for each team\n",
    "        team_features = {}\n",
    "        \n",
    "        for team in season_data['recent_team'].unique():\n",
    "            team_data = season_data[season_data['recent_team'] == team]\n",
    "            \n",
    "            if len(team_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # CRITICAL FIX: Aggregate player stats into team totals per week\n",
    "            # Group by week and sum all players' stats to get team totals\n",
    "            team_weekly = team_data.groupby('week').agg({\n",
    "                'passing_yards': 'sum',\n",
    "                'rushing_yards': 'sum',\n",
    "                'completions': 'sum',\n",
    "                'passing_tds': 'sum',\n",
    "                'interceptions': 'sum',\n",
    "                'rushing_tds': 'sum',\n",
    "                'fantasy_points': 'sum'\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Now calculate per-game averages from team totals\n",
    "            total_yards_per_week = team_weekly['passing_yards'] + team_weekly['rushing_yards']\n",
    "            \n",
    "            # Recent form (last 3 games)\n",
    "            recent_games = team_weekly.tail(3)\n",
    "            recent_points = recent_games['fantasy_points'].mean() if len(recent_games) > 0 else 0\n",
    "            recent_yards = (recent_games['passing_yards'] + recent_games['rushing_yards']).mean() if len(recent_games) > 0 else 0\n",
    "            \n",
    "            # Momentum tracking\n",
    "            if len(team_weekly) >= 3:\n",
    "                recent_3 = team_weekly.tail(3)['fantasy_points'].mean()\n",
    "                earlier_games = team_weekly.iloc[:-3]['fantasy_points'].mean() if len(team_weekly) > 3 else recent_3\n",
    "                points_trend = recent_3 - earlier_games\n",
    "                \n",
    "                recent_3_yards = (team_weekly.tail(3)['passing_yards'] + team_weekly.tail(3)['rushing_yards']).mean()\n",
    "                earlier_yards = (team_weekly.iloc[:-3]['passing_yards'] + team_weekly.iloc[:-3]['rushing_yards']).mean() if len(team_weekly) > 3 else recent_3_yards\n",
    "                yards_trend = recent_3_yards - earlier_yards\n",
    "                \n",
    "                # Calculate momentum as average of last 3 games relative to season average\n",
    "                season_avg = team_weekly['fantasy_points'].mean()\n",
    "                momentum = (recent_3 - season_avg) / (season_avg + 1)  # Normalized momentum\n",
    "            else:\n",
    "                points_trend = 0\n",
    "                yards_trend = 0\n",
    "                momentum = 0\n",
    "            \n",
    "            # Get defensive stats\n",
    "            def_stats = defensive_stats.get(team, {\n",
    "                'def_yards_allowed_pg': 0,\n",
    "                'def_points_allowed_pg': 0\n",
    "            })\n",
    "                \n",
    "            # Offensive features (from aggregated team data)\n",
    "            features = {\n",
    "                'passing_yards_pg': team_weekly['passing_yards'].mean(),\n",
    "                'rushing_yards_pg': team_weekly['rushing_yards'].mean(), \n",
    "                'total_yards_pg': total_yards_per_week.mean(),\n",
    "                'points_pg': team_weekly['fantasy_points'].mean(),\n",
    "                'completions_pg': team_weekly['completions'].mean(),\n",
    "                'passing_tds_pg': team_weekly['passing_tds'].mean(),\n",
    "                'interceptions_thrown_pg': team_weekly['interceptions'].mean(),\n",
    "                'rushing_tds_pg': team_weekly['rushing_tds'].mean(),\n",
    "                'fumbles_lost_pg': 0,  # Not available in weekly_data\n",
    "                \n",
    "                # Defensive features\n",
    "                'opp_total_yards_pg': def_stats['def_yards_allowed_pg'],\n",
    "                'opp_points_pg': def_stats['def_points_allowed_pg'],\n",
    "                \n",
    "                # Recent form (last 3 games)\n",
    "                'recent_points_pg': recent_points,\n",
    "                'recent_yards_pg': recent_yards,\n",
    "                \n",
    "                # Momentum indicators\n",
    "                'points_trend': points_trend,\n",
    "                'yards_trend': yards_trend,\n",
    "                \n",
    "                # Team health and availability metrics\n",
    "                'injury_percentage': self._calculate_injury_percentage(team_data),\n",
    "                'momentum_last3': momentum,  # PRIORITY 2: Win % in last 3 games\n",
    "                \n",
    "                # Advanced metrics\n",
    "                'turnover_ratio': team_weekly['interceptions'].mean(),\n",
    "                'games_played': len(team_weekly)\n",
    "            }\n",
    "            \n",
    "            team_features[team] = features\n",
    "        \n",
    "        return team_features\n",
    "    \n",
    "    def create_game_features(self, home_team, away_team, team_features, \n",
    "                           season, week, is_playoff=False, is_neutral=False,\n",
    "                           rest_days=7, is_division_game=False, vegas_spread=None):\n",
    "        \"\"\"\n",
    "        Create features for a specific matchup with defensive stats.\n",
    "        \n",
    "        PRIORITY 3 additions:\n",
    "        - rest_days: Days since last game (from schedule data)\n",
    "        - is_division_game: Boolean for rivalry matchups\n",
    "        - vegas_spread: Market spread if available\n",
    "        \"\"\"\n",
    "        \n",
    "        if home_team not in team_features or away_team not in team_features:\n",
    "            return None\n",
    "        \n",
    "        home_stats = team_features[home_team]\n",
    "        away_stats = team_features[away_team]\n",
    "        \n",
    "        # Create matchup features\n",
    "        features = {\n",
    "            # Home team offensive stats\n",
    "            'home_passing_ypg': home_stats['passing_yards_pg'],\n",
    "            'home_rushing_ypg': home_stats['rushing_yards_pg'],\n",
    "            'home_total_ypg': home_stats['total_yards_pg'],\n",
    "            'home_points_pg': home_stats['points_pg'],\n",
    "            'home_passing_tds_pg': home_stats['passing_tds_pg'],\n",
    "            'home_turnovers_pg': home_stats.get('fumbles_lost_pg', 0) + home_stats['interceptions_thrown_pg'],\n",
    "            'home_injury_pct': home_stats['injury_percentage'],\n",
    "            \n",
    "            # Home team defensive stats\n",
    "            'home_def_yards_allowed': home_stats.get('opp_total_yards_pg', 0),\n",
    "            'home_def_points_allowed': home_stats.get('opp_points_pg', 0),\n",
    "            \n",
    "            # Home team recent form\n",
    "            'home_recent_points': home_stats.get('recent_points_pg', home_stats['points_pg']),\n",
    "            'home_points_trend': home_stats.get('points_trend', 0),\n",
    "            \n",
    "            # Away team offensive stats  \n",
    "            'away_passing_ypg': away_stats['passing_yards_pg'],\n",
    "            'away_rushing_ypg': away_stats['rushing_yards_pg'],\n",
    "            'away_total_ypg': away_stats['total_yards_pg'],\n",
    "            'away_points_pg': away_stats['points_pg'],\n",
    "            'away_passing_tds_pg': away_stats['passing_tds_pg'],\n",
    "            'away_turnovers_pg': away_stats.get('fumbles_lost_pg', 0) + away_stats['interceptions_thrown_pg'],\n",
    "            'away_injury_pct': away_stats['injury_percentage'],\n",
    "            \n",
    "            # Away team defensive stats\n",
    "            'away_def_yards_allowed': away_stats.get('opp_total_yards_pg', 0),\n",
    "            'away_def_points_allowed': away_stats.get('opp_points_pg', 0),\n",
    "            \n",
    "            # Away team recent form\n",
    "            'away_recent_points': away_stats.get('recent_points_pg', away_stats['points_pg']),\n",
    "            'away_points_trend': away_stats.get('points_trend', 0),\n",
    "            \n",
    "            # Matchup advantages\n",
    "            'passing_advantage': home_stats['passing_yards_pg'] - away_stats['passing_yards_pg'],\n",
    "            'rushing_advantage': home_stats['rushing_yards_pg'] - away_stats['rushing_yards_pg'],\n",
    "            'scoring_advantage': home_stats['points_pg'] - away_stats['points_pg'],\n",
    "            'momentum_advantage': home_stats.get('momentum_last3', 0.5) - away_stats.get('momentum_last3', 0.5),  # PRIORITY 2\n",
    "            'turnover_advantage': away_stats.get('fumbles_lost_pg', 0) + away_stats['interceptions_thrown_pg'] - \n",
    "                                (home_stats.get('fumbles_lost_pg', 0) + home_stats['interceptions_thrown_pg']),\n",
    "            'injury_advantage': away_stats['injury_percentage'] - home_stats['injury_percentage'],\n",
    "            \n",
    "            # Defensive matchup advantages\n",
    "            'defensive_advantage': away_stats.get('opp_points_pg', 0) - home_stats.get('opp_points_pg', 0),\n",
    "            'offensive_vs_defense': home_stats['points_pg'] - away_stats.get('opp_points_pg', 25),\n",
    "            \n",
    "            # Game context\n",
    "            'home_field_advantage': 0 if is_neutral else 2.5,\n",
    "            'is_playoff': 1 if is_playoff else 0,\n",
    "            'is_neutral': 1 if is_neutral else 0,\n",
    "            'week': week,\n",
    "            'season': season,\n",
    "            \n",
    "            # PRIORITY 3: External features\n",
    "            'rest_days': rest_days,  # Days since last game\n",
    "            'is_division_game': 1 if is_division_game else 0,  # Rivalry indicator\n",
    "            'vegas_spread': vegas_spread if vegas_spread is not None else 0,  # Market expectation\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def build_dataset(self, pbp_data, weekly_data, schedule_data, save_csv=True, data_folder='nfl_data'):\n",
    "        \"\"\"Build complete dataset from NFL data and optionally save as CSV\"\"\"\n",
    "        \n",
    "        print(\"Building dataset from collected data...\")\n",
    "        print(f\"Processing {len(schedule_data)} scheduled games...\")\n",
    "        \n",
    "        game_records = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        # Process each scheduled game\n",
    "        for idx, game in schedule_data.iterrows():\n",
    "            processed_count += 1\n",
    "            if processed_count % 500 == 0:\n",
    "                print(f\"  Processed {processed_count}/{len(schedule_data)} games...\")\n",
    "            season = game['season']\n",
    "            week = game['week']\n",
    "            home_team = game['home_team']\n",
    "            away_team = game['away_team']\n",
    "            \n",
    "            # Skip if missing essential data\n",
    "            if pd.isna(home_team) or pd.isna(away_team):\n",
    "                continue\n",
    "            \n",
    "            # Get team features up to this point in season (with defensive stats)\n",
    "            team_features = self.create_team_features(weekly_data, season, week, schedule_data)\n",
    "            \n",
    "            if not team_features:\n",
    "                continue\n",
    "            \n",
    "            # Create game features\n",
    "            game_features = self.create_game_features(\n",
    "                home_team, away_team, team_features, \n",
    "                season, week,\n",
    "                is_playoff=game.get('game_type', '') == 'REG',\n",
    "                is_neutral=False  # Simplified for now\n",
    "            )\n",
    "            \n",
    "            if game_features is None:\n",
    "                continue\n",
    "            \n",
    "            # Determine result (home team win = 1, loss = 0)\n",
    "            home_score = game.get('home_score', 0)\n",
    "            away_score = game.get('away_score', 0)\n",
    "            \n",
    "            # Skip games without scores (future games)\n",
    "            if pd.isna(home_score) or pd.isna(away_score):\n",
    "                continue\n",
    "            \n",
    "            game_features['home_win'] = 1 if home_score > away_score else 0\n",
    "            game_features['home_score'] = home_score\n",
    "            game_features['away_score'] = away_score\n",
    "            game_features['game_id'] = f\"{season}_{week}_{home_team}_{away_team}\"\n",
    "            \n",
    "            game_records.append(game_features)\n",
    "        \n",
    "        df = pd.DataFrame(game_records)\n",
    "        print(f\"Created dataset with {len(df)} games\")\n",
    "        \n",
    "        # Save the processed dataset\n",
    "        if save_csv and not df.empty:\n",
    "            if not os.path.exists(data_folder):\n",
    "                os.makedirs(data_folder)\n",
    "            \n",
    "            processed_file = os.path.join(data_folder, 'processed_game_features.csv')\n",
    "            df.to_csv(processed_file, index=False)\n",
    "            print(f\"✓ Saved processed game features: {processed_file} ({len(df):,} rows)\")\n",
    "            \n",
    "            # Show feature information\n",
    "            print(f\"\\nPROCESSED FEATURES ({len(df.columns)} columns):\")\n",
    "            print(\"=\"*50)\n",
    "            for col in df.columns:\n",
    "                print(f\"  - {col}\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def select_features(self, df, n_features=20):\n",
    "        \"\"\"Select best features using RFE with expanded feature set\"\"\"\n",
    "        \n",
    "        # Prepare data\n",
    "        feature_cols = [col for col in df.columns \n",
    "                       if col not in ['home_win', 'home_score', 'away_score', 'game_id']]\n",
    "        \n",
    "        X = df[feature_cols]\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # Remove any columns with all NaN or constant values\n",
    "        X = X.loc[:, X.var() > 0]\n",
    "        X = X.fillna(X.mean())\n",
    "        \n",
    "        print(f\"Starting feature selection with {len(X.columns)} features...\")\n",
    "        print(f\"Testing up to {n_features} features for best performance...\")\n",
    "        \n",
    "        # Use RFE with different numbers of features\n",
    "        models = {}\n",
    "        results = []\n",
    "        \n",
    "        for i in range(2, min(n_features + 1, len(X.columns) + 1)):\n",
    "            rfe = RFE(estimator=LDA(), n_features_to_select=i)\n",
    "            model = DecisionTreeClassifier(random_state=42)\n",
    "            pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "            \n",
    "            cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "            scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "            \n",
    "            results.append(scores)\n",
    "            models[str(i)] = pipeline\n",
    "            \n",
    "            print(f'{i} features: {scores.mean():.3f} (+/- {scores.std():.3f})')\n",
    "        \n",
    "        # Find best number of features\n",
    "        best_idx = np.argmax([np.mean(result) for result in results])\n",
    "        best_n_features = best_idx + 2\n",
    "        \n",
    "        print(f\"\\nBest number of features: {best_n_features}\")\n",
    "        \n",
    "        # Get the best feature set\n",
    "        rfe = RFE(estimator=LDA(), n_features_to_select=best_n_features)\n",
    "        rfe.fit(X, y)\n",
    "        \n",
    "        selected_features = X.columns[rfe.support_].tolist()\n",
    "        self.best_features = selected_features\n",
    "        \n",
    "        print(\"\\nSelected features:\")\n",
    "        for feature in selected_features:\n",
    "            print(f\"  - {feature}\")\n",
    "        \n",
    "        return selected_features\n",
    "    \n",
    "    def train_models(self, df):\n",
    "        \"\"\"Train and compare multiple models\"\"\"\n",
    "        \n",
    "        if not self.best_features:\n",
    "            self.select_features(df)\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Define models to test\n",
    "        models_to_test = {\n",
    "            'Logistic Regression': LogisticRegression(random_state=42),\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "            'Random Forest': RandomForestClassifier(random_state=42)\n",
    "        }\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            models_to_test['XGBoost'] = xgb.XGBClassifier(random_state=42, verbosity=0)\n",
    "        \n",
    "        # Train and evaluate models\n",
    "        model_results = {}\n",
    "        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "        \n",
    "        print(\"\\nTraining and evaluating models...\")\n",
    "        \n",
    "        for name, model in models_to_test.items():\n",
    "            # Use scaled data for logistic regression, raw for tree-based\n",
    "            X_use = X_train_scaled if 'Logistic' in name else X_train\n",
    "            scores = cross_val_score(model, X_use, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "            \n",
    "            model_results[name] = {\n",
    "                'mean_score': scores.mean(),\n",
    "                'std_score': scores.std(),\n",
    "                'scores': scores\n",
    "            }\n",
    "            \n",
    "            print(f\"{name}: {scores.mean():.3f} (+/- {scores.std():.3f})\")\n",
    "        \n",
    "        self.models = models_to_test\n",
    "        return model_results\n",
    "    \n",
    "    def tune_best_model(self, df, model_name='Random Forest'):\n",
    "        \"\"\"Tune hyperparameters for the best performing model\"\"\"\n",
    "        \n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        if model_name == 'Random Forest':\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300, 400, 500],\n",
    "                'max_depth': [8, 9, 10, 11, 12],\n",
    "                'min_samples_leaf': [2, 5],\n",
    "                'criterion': ['gini', 'entropy']\n",
    "            }\n",
    "            model = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        elif model_name == 'Logistic Regression':\n",
    "            param_grid = {\n",
    "                'C': [0.01, 0.1, 1, 10, 100],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'solver': ['liblinear']\n",
    "            }\n",
    "            model = LogisticRegression(random_state=42)\n",
    "            X_train = self.scaler.fit_transform(X_train)\n",
    "            X_test = self.scaler.transform(X_test)\n",
    "        \n",
    "        elif model_name == 'XGBoost' and HAS_XGB:\n",
    "            param_grid = {\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1, 0.2],\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'reg_alpha': [0, 1],\n",
    "            'reg_lambda': [1, 5]\n",
    "            }\n",
    "            model = xgb.XGBClassifier(random_state=42, verbosity=0)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Tuning not implemented for {model_name}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, \n",
    "            cv=5, scoring='accuracy', \n",
    "            n_jobs=-1, verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "        \n",
    "        # Test on holdout set\n",
    "        test_score = grid_search.score(X_test, y_test)\n",
    "        print(f\"Test set accuracy: {test_score:.3f}\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def create_ensemble_model(self, df):\n",
    "        \"\"\"\n",
    "        Create ensemble model combining multiple algorithms.\n",
    "        \n",
    "        IMPROVEMENTS IMPLEMENTED:\n",
    "        - Priority 1: Increased tree depths (RF: 5→15, XGB: 5→8) with regularization\n",
    "        - Priority 1: Added Gradient Boosting as 4th estimator\n",
    "        - Priority 2: Temporal weighting (2024 data weighted ~3x vs 2015)\n",
    "        - Priority 4: Better calibration approach\n",
    "        Expected: +3-5% accuracy improvement\n",
    "        \"\"\"\n",
    "        \n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # PRIORITY 2: Apply temporal weighting with exponential decay\n",
    "        sample_weights = None\n",
    "        if 'season' in df.columns:\n",
    "            current_year = df['season'].max()\n",
    "            years_ago = current_year - df['season']\n",
    "            # weight = exp(-0.15 * years_ago) makes 2024 ~3x heavier than 2015\n",
    "            sample_weights = np.exp(-0.15 * years_ago)\n",
    "            sample_weights = sample_weights / sample_weights.mean()  # Normalize\n",
    "            recent_weight = sample_weights[df['season']==current_year].mean() if (df['season']==current_year).any() else 1.0\n",
    "            old_weight = sample_weights[df['season']==current_year-9].mean() if (df['season']==current_year-9).any() else 1.0\n",
    "            print(f\"Temporal weighting: {current_year} data = {recent_weight:.2f}x, {current_year-9} data = {old_weight:.2f}x\")\n",
    "        \n",
    "        # PRIORITY 1: Deeper Random Forest (5→15) with overfitting protection\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=15,  # CHANGED from 5\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=4,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Logistic Regression baseline\n",
    "        lr = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "        \n",
    "        estimators = [('rf', rf), ('lr', lr)]\n",
    "        \n",
    "        # PRIORITY 1: Deeper XGBoost (5→8) with stronger regularization\n",
    "        if HAS_XGB:\n",
    "            xgb_model = xgb.XGBClassifier(\n",
    "                max_depth=8,          # CHANGED from 5\n",
    "                learning_rate=0.1,\n",
    "                n_estimators=200,\n",
    "                reg_alpha=0.5,        # L1 regularization (NEW)\n",
    "                reg_lambda=1.0,       # L2 regularization (NEW)\n",
    "                subsample=0.8,        # Row sampling (NEW)\n",
    "                colsample_bytree=0.8, # Column sampling (NEW)\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "            estimators.append(('xgb', xgb_model))\n",
    "        \n",
    "        # PRIORITY 1: Add Gradient Boosting for ensemble diversity (4th model)\n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        estimators.append(('gb', gb))\n",
    "        \n",
    "        print(f\"Ensemble models: {', '.join([name for name, _ in estimators])}\")\n",
    "        \n",
    "        # Voting classifier with soft voting\n",
    "        voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "        \n",
    "        # Calibrated classifier for probability estimates\n",
    "        self.final_model = CCV(voting_clf, method='isotonic', cv=3)\n",
    "        \n",
    "        print(f\"Training ensemble ({len(estimators)} models)\" + (\" with temporal weighting...\" if sample_weights is not None else \"...\"))\n",
    "        \n",
    "        # Fit with sample weights if available\n",
    "        if sample_weights is not None:\n",
    "            # Train each base estimator with weights before voting\n",
    "            for name, est in voting_clf.estimators:\n",
    "                if hasattr(est, 'fit') and 'sample_weight' in est.fit.__code__.co_varnames:\n",
    "                    est.fit(X, y, sample_weight=sample_weights)\n",
    "                    print(f\"  {name}: trained with weights\")\n",
    "                else:\n",
    "                    est.fit(X, y)\n",
    "                    print(f\"  {name}: trained (no weight support)\")\n",
    "        \n",
    "        # Fit calibrated model\n",
    "        self.final_model.fit(X, y)\n",
    "        print(\"✓ Ensemble complete!\")\n",
    "        \n",
    "        return self.final_model\n",
    "    \n",
    "    def evaluate_model_with_calibration(self, df):\n",
    "        \"\"\"\n",
    "        Evaluate model with advanced metrics including calibration.\n",
    "        \n",
    "        PRIORITY 4: Proper time-series cross-validation and calibration metrics\n",
    "        - Uses TimeSeriesSplit to respect temporal order\n",
    "        - Calculates Brier score (calibration metric)\n",
    "        - Calculates log loss (probability quality)\n",
    "        \"\"\"\n",
    "        \n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['home_win']\n",
    "        \n",
    "        # TimeSeriesSplit for proper temporal validation\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        accuracies = []\n",
    "        brier_scores = []\n",
    "        log_losses = []\n",
    "        \n",
    "        print(\"\\nTime-Series Cross-Validation:\")\n",
    "        for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Clone and fit model\n",
    "            from sklearn.base import clone\n",
    "            fold_model = clone(self.final_model)\n",
    "            fold_model.fit(X_train, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = fold_model.predict(X_test)\n",
    "            y_prob = fold_model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Metrics\n",
    "            acc = (y_pred == y_test).mean()\n",
    "            brier = brier_score_loss(y_test, y_prob)\n",
    "            logloss = log_loss(y_test, y_prob)\n",
    "            \n",
    "            accuracies.append(acc)\n",
    "            brier_scores.append(brier)\n",
    "            log_losses.append(logloss)\n",
    "            \n",
    "            print(f\"  Fold {fold}: Acc={acc:.3f}, Brier={brier:.4f}, LogLoss={logloss:.4f}\")\n",
    "        \n",
    "        print(f\"\\nMean Metrics:\")\n",
    "        print(f\"  Accuracy: {np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\")\n",
    "        print(f\"  Brier Score: {np.mean(brier_scores):.4f} ± {np.std(brier_scores):.4f}\")\n",
    "        print(f\"  Log Loss: {np.mean(log_losses):.4f} ± {np.std(log_losses):.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': np.mean(accuracies),\n",
    "            'brier_score': np.mean(brier_scores),\n",
    "            'log_loss': np.mean(log_losses),\n",
    "            'accuracy_std': np.std(accuracies)\n",
    "        }\n",
    "\n",
    "    \n",
    "    def predict_games(self, games_df, confidence_threshold=0.6):\n",
    "        \"\"\"Make predictions on new games\"\"\"\n",
    "        \n",
    "        if self.final_model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call create_ensemble_model() first.\")\n",
    "        \n",
    "        X = games_df[self.best_features].fillna(games_df[self.best_features].mean())\n",
    "        \n",
    "        # Get probability predictions\n",
    "        probabilities = self.final_model.predict_proba(X)[:, 1]\n",
    "        predictions = self.final_model.predict(X)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = games_df.copy()\n",
    "        results['home_win_prob'] = probabilities\n",
    "        results['predicted_home_win'] = predictions\n",
    "        \n",
    "        # High-confidence bets\n",
    "        results['high_confidence_bet'] = (\n",
    "            (probabilities >= confidence_threshold) | \n",
    "            (probabilities <= (1 - confidence_threshold))\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Initialize predictor\n",
    "    predictor = NFLGamePredictor()\n",
    "    \n",
    "    # Check if nfl_data_py is available\n",
    "    if not HAS_NFL_DATA:\n",
    "        print(\"Please install nfl_data_py to use this predictor:\")\n",
    "        print(\"pip install nfl_data_py\")\n",
    "        exit()\n",
    "    \n",
    "    try:\n",
    "        # Collect data (this may take a few minutes)\n",
    "        print(\"This may take a few minutes to download NFL data...\")\n",
    "        pbp_data, weekly_data, schedule_data, team_dict = predictor.collect_data(2015, 2025, save_csv=True)\n",
    "        \n",
    "        # Build dataset\n",
    "        df = predictor.build_dataset(pbp_data, weekly_data, schedule_data, save_csv=True)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"No data collected. Check your internet connection and try again.\")\n",
    "            exit()\n",
    "        \n",
    "        # Feature selection with expanded feature set (20 features)\n",
    "        predictor.select_features(df, n_features=20)\n",
    "        \n",
    "        # Train models\n",
    "        model_results = predictor.train_models(df)\n",
    "        \n",
    "        # Create ensemble\n",
    "        final_model = predictor.create_ensemble_model(df)\n",
    "        \n",
    "        # Example prediction on test set\n",
    "        train_data = df[df['season'] < 2023]\n",
    "        test_data = df[df['season'] == 2023]\n",
    "        \n",
    "        if not test_data.empty:\n",
    "            predictor.final_model.fit(\n",
    "                train_data[predictor.best_features].fillna(train_data[predictor.best_features].mean()), \n",
    "                train_data['home_win']\n",
    "            )\n",
    "            \n",
    "            predictions = predictor.predict_games(test_data)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (predictions['predicted_home_win'] == predictions['home_win']).mean()\n",
    "            print(f\"\\n2023 season prediction accuracy: {accuracy:.3f}\")\n",
    "            \n",
    "            # High confidence bets\n",
    "            high_conf = predictions[predictions['high_confidence_bet']]\n",
    "            if not high_conf.empty:\n",
    "                conf_accuracy = (high_conf['predicted_home_win'] == high_conf['home_win']).mean()\n",
    "                print(f\"High confidence bet accuracy: {conf_accuracy:.3f} ({len(high_conf)} games)\")\n",
    "        \n",
    "        print(\"\\nPredictor trained successfully!\")\n",
    "        print(\"You can now use predictor.predict_games() on new data.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "\n",
    "joblib.dump(predictor.final_model, 'final_model.joblib')\n",
    "\n",
    "# To load later:\n",
    "# predictor.final_model = joblib.load('nfl_data/final_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357daa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFL SPREAD PREDICTION MODEL\n",
    "# Enhanced version that predicts point spreads instead of just winners\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "class NFLSpreadPredictor:\n",
    "    def __init__(self):\n",
    "        self.spread_model = None\n",
    "        self.best_features = []\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def prepare_spread_data(self, df):\n",
    "        \"\"\"Convert winner prediction data to spread prediction data\"\"\"\n",
    "        \n",
    "        # Create point differential (home_score - away_score)\n",
    "        df['point_spread'] = df['home_score'] - df['away_score']\n",
    "        \n",
    "        print(f\"Spread Data Summary:\")\n",
    "        print(f\"  Games: {len(df)}\")\n",
    "        print(f\"  Average spread: {df['point_spread'].mean():.1f} points\")\n",
    "        print(f\"  Spread range: {df['point_spread'].min():.0f} to {df['point_spread'].max():.0f}\")\n",
    "        print(f\"  Home team wins: {(df['point_spread'] > 0).sum()} ({(df['point_spread'] > 0).mean():.1%})\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train_spread_model(self, df, use_existing_features=True):\n",
    "        \"\"\"Train regression model to predict point spreads\"\"\"\n",
    "        \n",
    "        # Prepare spread data\n",
    "        df = self.prepare_spread_data(df)\n",
    "        \n",
    "        # Use existing features or select new ones for regression\n",
    "        if use_existing_features and hasattr(predictor, 'best_features') and predictor.best_features:\n",
    "            self.best_features = predictor.best_features\n",
    "            print(f\"Using existing features: {len(self.best_features)} features\")\n",
    "        else:\n",
    "            # Select features for regression\n",
    "            feature_cols = [col for col in df.columns \n",
    "                           if col not in ['home_win', 'home_score', 'away_score', 'game_id', 'point_spread']]\n",
    "            self.best_features = feature_cols[:15]  # Use top 15 features\n",
    "            print(f\"Selected {len(self.best_features)} features for spread prediction\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[self.best_features].fillna(df[self.best_features].mean())\n",
    "        y = df['point_spread']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # PRIORITY 5: Improved regression models with GradientBoosting\n",
    "        models = {\n",
    "            'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=12, random_state=42),\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(\n",
    "                n_estimators=200,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                loss='quantile',  # Better for spread prediction\n",
    "                alpha=0.5,  # Median prediction\n",
    "                subsample=0.8,\n",
    "                random_state=42\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        if HAS_XGB:\n",
    "            models['XGBoost'] = xgb.XGBRegressor(\n",
    "                n_estimators=200,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                reg_alpha=0.5,  # L1 regularization\n",
    "                reg_lambda=1.0,  # L2 regularization\n",
    "                random_state=42,\n",
    "                verbosity=0\n",
    "            )\n",
    "        \n",
    "        print(\"\\nTraining spread prediction models...\")\n",
    "        best_model = None\n",
    "        best_mae = float('inf')\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            # Use scaled data for linear regression, raw for tree-based\n",
    "            X_use_train = X_train_scaled if 'Linear' in name else X_train\n",
    "            X_use_test = X_test_scaled if 'Linear' in name else X_test\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_use_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_use_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            print(f\"{name}:\")\n",
    "            print(f\"  MAE: {mae:.2f} points\")\n",
    "            print(f\"  RMSE: {rmse:.2f} points\")\n",
    "            print(f\"  R²: {r2:.3f}\")\n",
    "            \n",
    "            # Select best model based on MAE\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_model = model\n",
    "                self.spread_model = model\n",
    "                print(f\"  *** NEW BEST MODEL ***\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"Best model MAE: {best_mae:.2f} points\")\n",
    "        return self.spread_model\n",
    "    \n",
    "    def predict_spreads(self, games_df):\n",
    "        \"\"\"Predict point spreads for new games\"\"\"\n",
    "        \n",
    "        if self.spread_model is None:\n",
    "            raise ValueError(\"Spread model not trained yet!\")\n",
    "        \n",
    "        X = games_df[self.best_features].fillna(games_df[self.best_features].mean())\n",
    "        \n",
    "        # Use appropriate scaling based on model type\n",
    "        if 'Linear' in str(type(self.spread_model)):\n",
    "            X = self.scaler.transform(X)\n",
    "        \n",
    "        # Get spread predictions\n",
    "        predicted_spreads = self.spread_model.predict(X)\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = games_df.copy()\n",
    "        results['predicted_spread'] = predicted_spreads\n",
    "        \n",
    "        # Determine winner based on spread\n",
    "        results['predicted_winner_spread'] = np.where(\n",
    "            predicted_spreads > 0, \n",
    "            results.get('home_team', 'HOME'),  # Home team wins if spread > 0\n",
    "            results.get('away_team', 'AWAY')   # Away team wins if spread < 0\n",
    "        )\n",
    "        \n",
    "        # IMPROVED: Better confidence calculation based on spread magnitude\n",
    "        # Confidence increases with spread size (more certain about blowouts)\n",
    "        # Formula: 0.50 + min(0.45, abs(spread) * 0.025)\n",
    "        # Results: 0 spread = 50%, 10 pt spread = 75%, 18+ pt spread = 95%\n",
    "        base_confidence = 0.50\n",
    "        spread_factor = np.abs(predicted_spreads) * 0.025\n",
    "        results['spread_confidence'] = np.clip(base_confidence + spread_factor, 0.50, 0.95)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize spread predictor\n",
    "spread_predictor = NFLSpreadPredictor()\n",
    "\n",
    "print(\"NFL SPREAD PREDICTION MODEL READY!\")\n",
    "print(\"\\nThis model predicts:\")\n",
    "print(\"  - Point spreads (e.g., Chiefs -7.5)\")\n",
    "print(\"  - How much teams will win/lose by\")\n",
    "print(\"  - More detailed game analysis\")\n",
    "print(\"\\nNext: Train the spread model using existing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE SPREAD MODEL\n",
    "print(\"TRAINING NFL SPREAD PREDICTION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if we have the original data\n",
    "if 'df' in locals() or 'df' in globals():\n",
    "    try:\n",
    "        # Train spread model using existing dataset\n",
    "        print(\"Training spread model on historical data...\")\n",
    "        \n",
    "        spread_model = spread_predictor.train_spread_model(df, use_existing_features=True)\n",
    "        \n",
    "        if spread_model is not None:\n",
    "            print(\"✓ Spread model trained successfully!\")\n",
    "            print(\"\\nModel can now predict:\")\n",
    "            print(\"  - Point spreads (e.g., 'Chiefs -7.5')\")\n",
    "            print(\"  - Victory margins\")\n",
    "            print(\"  - Game competitiveness\")\n",
    "            \n",
    "            # Test on a few sample games\n",
    "            print(f\"\\nTesting on recent games...\")\n",
    "            test_games = df.tail(3)\n",
    "            if not test_games.empty:\n",
    "                spread_results = spread_predictor.predict_spreads(test_games)\n",
    "                \n",
    "                print(\"Sample predictions:\")\n",
    "                for _, game in spread_results.iterrows():\n",
    "                    home_team = game.get('game_id', 'Unknown').split('_')[-2] if 'game_id' in game else 'HOME'\n",
    "                    away_team = game.get('game_id', 'Unknown').split('_')[-1] if 'game_id' in game else 'AWAY'\n",
    "                    spread = game['predicted_spread']\n",
    "                    actual_spread = game.get('point_spread', 0)\n",
    "                    \n",
    "                    if spread > 0:\n",
    "                        print(f\"  {home_team} -{abs(spread):.1f} vs {away_team} (actual: {actual_spread:+.0f})\")\n",
    "                    else:\n",
    "                        print(f\"  {away_team} -{abs(spread):.1f} vs {home_team} (actual: {actual_spread:+.0f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training spread model: {e}\")\n",
    "        print(\"Make sure the original model data is available.\")\n",
    "        \n",
    "else:\n",
    "    print(\"ERROR: No training data found!\")\n",
    "    print(\"Please run Step 2 first to collect and prepare the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f84d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED SPREAD PREDICTION FUNCTION\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def predict_multiple_games_with_spreads(predictor, spread_predictor, games_text, season=2025, week=6, show_details=True):\n",
    "    \"\"\"\n",
    "    Predict multiple games with BOTH winner probabilities AND point spreads\n",
    "    \n",
    "    Args:\n",
    "        predictor: Trained NFLGamePredictor instance (for winner predictions)\n",
    "        spread_predictor: Trained NFLSpreadPredictor instance (for spread predictions)\n",
    "        games_text: Formatted text with games\n",
    "        season: Season year\n",
    "        week: Week number\n",
    "        show_details: Whether to show detailed output\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with both winner and spread predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    if predictor.final_model is None:\n",
    "        return None\n",
    "        \n",
    "    if spread_predictor.spread_model is None:\n",
    "        return None\n",
    "    \n",
    "    # Use existing team mapping from original function\n",
    "    team_mapping = {\n",
    "        'TB Buccaneers': 'TB', 'Tampa Bay Buccaneers': 'TB', 'TB': 'TB',\n",
    "        'ATL Falcons': 'ATL', 'Atlanta Falcons': 'ATL', 'ATL': 'ATL',\n",
    "        'CIN Bengals': 'CIN', 'Cincinnati Bengals': 'CIN', 'CIN': 'CIN',\n",
    "        'CLE Browns': 'CLE', 'Cleveland Browns': 'CLE', 'CLE': 'CLE',\n",
    "        'MIA Dolphins': 'MIA', 'Miami Dolphins': 'MIA', 'MIA': 'MIA',\n",
    "        'IND Colts': 'IND', 'Indianapolis Colts': 'IND', 'IND': 'IND',\n",
    "        'CAR Panthers': 'CAR', 'Carolina Panthers': 'CAR', 'CAR': 'CAR',\n",
    "        'JAX Jaguars': 'JAX', 'Jacksonville Jaguars': 'JAX', 'JAX': 'JAX',\n",
    "        'LV Raiders': 'LV', 'Las Vegas Raiders': 'LV', 'LV': 'LV',\n",
    "        'NE Patriots': 'NE', 'New England Patriots': 'NE', 'NE': 'NE',\n",
    "        'ARI Cardinals': 'ARI', 'Arizona Cardinals': 'ARI', 'ARI': 'ARI',\n",
    "        'NO Saints': 'NO', 'New Orleans Saints': 'NO', 'NO': 'NO',\n",
    "        'PIT Steelers': 'PIT', 'Pittsburgh Steelers': 'PIT', 'PIT': 'PIT',\n",
    "        'NYJ Jets': 'NYJ', 'New York Jets': 'NYJ', 'NYJ': 'NYJ',\n",
    "        'NYG Giants': 'NYG', 'New York Giants': 'NYG', 'NYG': 'NYG',\n",
    "        'WAS Commanders': 'WAS', 'Washington Commanders': 'WAS', 'WAS': 'WAS',\n",
    "        'TEN Titans': 'TEN', 'Tennessee Titans': 'TEN', 'TEN': 'TEN',\n",
    "        'DEN Broncos': 'DEN', 'Denver Broncos': 'DEN', 'DEN': 'DEN',\n",
    "        'SF 49ers': 'SF', 'San Francisco 49ers': 'SF', 'SF': 'SF',\n",
    "        'SEA Seahawks': 'SEA', 'Seattle Seahawks': 'SEA', 'SEA': 'SEA',\n",
    "        'DET Lions': 'DET', 'Detroit Lions': 'DET', 'DET': 'DET',\n",
    "        'GB Packers': 'GB', 'Green Bay Packers': 'GB', 'GB': 'GB',\n",
    "        'HOU Texans': 'HOU', 'Houston Texans': 'HOU', 'HOU': 'HOU',\n",
    "        'LA Rams': 'LA', 'Los Angeles Rams': 'LA', 'LA': 'LA',\n",
    "        'LAR Rams': 'LA', 'Los Angeles Rams': 'LA', 'LAR': 'LA',\n",
    "        'BAL Ravens': 'BAL', 'Baltimore Ravens': 'BAL', 'BAL': 'BAL',\n",
    "        'BUF Bills': 'BUF', 'Buffalo Bills': 'BUF', 'BUF': 'BUF',\n",
    "        'KC Chiefs': 'KC', 'Kansas City Chiefs': 'KC', 'KC': 'KC',\n",
    "        'PHI Eagles': 'PHI', 'Philadelphia Eagles': 'PHI', 'PHI': 'PHI',\n",
    "        'DAL Cowboys': 'DAL', 'Dallas Cowboys': 'DAL', 'DAL': 'DAL',\n",
    "        'MIN Vikings': 'MIN', 'Minnesota Vikings': 'MIN', 'MIN': 'MIN',\n",
    "        'CHI Bears': 'CHI', 'Chicago Bears': 'CHI', 'CHI': 'CHI',\n",
    "        'LAC Chargers': 'LAC', 'Los Angeles Chargers': 'LAC', 'LAC': 'LAC'\n",
    "    }\n",
    "    \n",
    "    # Parse games\n",
    "    game_pattern = r'\\(Away\\)\\s+(.*?)\\s+vs\\.\\s+\\(Home\\)\\s+(.*)'\n",
    "    matches = re.findall(game_pattern, games_text, re.IGNORECASE)\n",
    "    \n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    # Get team features\n",
    "    try:\n",
    "        team_features = predictor.create_team_features(weekly_data, 2025, week, schedule_data)\n",
    "        if not team_features:\n",
    "            team_features = predictor.create_team_features(weekly_data, 2024, 19, schedule_data)\n",
    "            data_source = \"2024 season-end\"\n",
    "        else:\n",
    "            data_source = f\"2025 Week {week-1}\"\n",
    "            \n",
    "        if not team_features:\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    all_predictions = []\n",
    "    successful_predictions = 0\n",
    "    \n",
    "    for i, (away_full, home_full) in enumerate(matches, 1):\n",
    "        away_full = away_full.strip()\n",
    "        home_full = home_full.strip()\n",
    "        \n",
    "        # Map to abbreviations\n",
    "        away_team = team_mapping.get(away_full, away_full.split()[-1] if away_full.split() else away_full)\n",
    "        home_team = team_mapping.get(home_full, home_full.split()[-1] if home_full.split() else home_full)\n",
    "        \n",
    "        away_team = away_team.strip().upper()\n",
    "        home_team = home_team.strip().upper()\n",
    "        \n",
    "        try:\n",
    "            # Check if teams exist\n",
    "            if away_team not in team_features or home_team not in team_features:\n",
    "                continue\n",
    "            \n",
    "            # Create game features\n",
    "            game_features = predictor.create_game_features(\n",
    "                home_team, away_team, team_features,\n",
    "                season, week, is_playoff=False, is_neutral=False\n",
    "            )\n",
    "            \n",
    "            if game_features is None:\n",
    "                continue\n",
    "            \n",
    "            game_df = pd.DataFrame([game_features])\n",
    "            \n",
    "            # Get BOTH winner and spread predictions\n",
    "            winner_result = predictor.predict_games(game_df)\n",
    "            spread_result = spread_predictor.predict_spreads(game_df)\n",
    "            \n",
    "            # Extract results\n",
    "            home_win_prob = winner_result['home_win_prob'].iloc[0]\n",
    "            predicted_home_win = winner_result['predicted_home_win'].iloc[0]\n",
    "            predicted_spread = spread_result['predicted_spread'].iloc[0]\n",
    "            \n",
    "            # CRITICAL: Ensure spread and winner are consistent\n",
    "            # The team with the negative spread MUST be the predicted winner\n",
    "            # Calculate confidence based on spread: Win Probability ≈ 50% + (spread × 2.5%)\n",
    "            spread_magnitude = abs(predicted_spread)\n",
    "            spread_based_confidence = 0.50 + (spread_magnitude * 0.025)\n",
    "            spread_based_confidence = min(spread_based_confidence, 0.95)  \n",
    "            \n",
    "            if predicted_spread > 0:\n",
    "                # Home team favored (positive spread means home team wins)\n",
    "                spread_display = f\"{home_team} -{abs(predicted_spread):.1f}\"\n",
    "                favored_team = home_team\n",
    "                winner = home_team  # Winner must match the favored team\n",
    "                confidence = spread_based_confidence\n",
    "            else:\n",
    "                # Away team favored (negative spread means away team wins)\n",
    "                spread_display = f\"{away_team} -{abs(predicted_spread):.1f}\"\n",
    "                favored_team = away_team\n",
    "                winner = away_team  # Winner must match the favored team\n",
    "                confidence = spread_based_confidence\n",
    "            \n",
    "            # Store comprehensive prediction\n",
    "            prediction_data = {\n",
    "                'game_num': i,\n",
    "                'away_team': away_team,\n",
    "                'home_team': home_team,\n",
    "                'matchup': f\"{away_team} @ {home_team}\",\n",
    "                'predicted_winner': winner,\n",
    "                'confidence': confidence,\n",
    "                'home_win_prob': home_win_prob,\n",
    "                'away_win_prob': 1 - home_win_prob,\n",
    "                'predicted_spread': predicted_spread,\n",
    "                'spread_display': spread_display,\n",
    "                'favored_team': favored_team,\n",
    "                'spread_magnitude': abs(predicted_spread)\n",
    "            }\n",
    "            \n",
    "            all_predictions.append(prediction_data)\n",
    "            successful_predictions += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if not all_predictions:\n",
    "        return None\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "print(\"ENHANCED SPREAD PREDICTION FUNCTION READY!\")\n",
    "print(\"\\nThis function provides:\")\n",
    "print(\"  - Winner predictions with confidence\")\n",
    "print(\"  - Point spread predictions\")\n",
    "print(\"  - Game competitiveness analysis\")\n",
    "print(\"  - Betting-focused insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ab5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE WEEK 10 SPREAD PREDICTIONS\n",
    "print(\"EXECUTING NFL WEEK 10 SPREAD PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Week 10 Complete Schedule (November 2025)\n",
    "week10_games = \"\"\"\n",
    "(Away) Las Vegas Raiders vs. (Home) Denver Broncos\n",
    "(Away) Atlanta Falcons vs. (Home) Indianapolis Colts\n",
    "(Away) New York Giants vs. (Home) Chicago Bears\n",
    "(Away) Buffalo Bills vs. (Home) Miami Dolphins\n",
    "(Away) Baltimore Ravens vs. (Home) Minnesota Vikings\n",
    "(Away) Cleveland Browns vs. (Home) New York Jets\n",
    "(Away) New England Patriots vs. (Home) Tampa Bay Buccaneers\n",
    "(Away) New Orleans Saints vs. (Home) Carolina Panthers\n",
    "(Away) Jacksonville Jaguars vs. (Home) Houston Texans\n",
    "(Away) Arizona Cardinals vs. (Home) Seattle Seahawks\n",
    "(Away) Los Angeles Rams vs. (Home) San Francisco 49ers\n",
    "(Away) Detroit Lions vs. (Home) Washington Commanders\n",
    "(Away) Pittsburgh Steelers vs. (Home) Los Angeles Chargers\n",
    "(Away) Philadelphia Eagles vs. (Home) Green Bay Packers\n",
    "\"\"\"\n",
    "\n",
    "# Check if both models are trained\n",
    "if ('predictor' in locals() and hasattr(predictor, 'final_model') and predictor.final_model is not None and\n",
    "    'spread_predictor' in locals() and hasattr(spread_predictor, 'spread_model') and spread_predictor.spread_model is not None):\n",
    "    \n",
    "    print(\"Both models are trained and ready!\")\n",
    "    print(\"Generating comprehensive predictions with spreads...\")\n",
    "    print()\n",
    "\n",
    "    # Run enhanced predictions with spreads\n",
    "    week10_spread_results = predict_multiple_games_with_spreads(\n",
    "        predictor, spread_predictor, week10_games, \n",
    "        season=2025, week=10, show_details=False\n",
    "    )\n",
    "\n",
    "    if week10_spread_results is not None:\n",
    "        print(f\"\\n\\nWEEK 10 PREDICTIONS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'MATCHUP':<20} {'SPREAD':<15} {'WINNER':<12} {'CONFIDENCE':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        # Week 10 game schedule\n",
    "        game_schedule = {\n",
    "            'LV @ DEN': ('Thursday', '8:15 PM ET'),\n",
    "            'ATL @ IND': ('Sunday', '9:30 AM ET'),\n",
    "            'NYG @ CHI': ('Sunday', '1:00 PM ET'),\n",
    "            'BUF @ MIA': ('Sunday', '1:00 PM ET'),\n",
    "            'BAL @ MIN': ('Sunday', '1:00 PM ET'),\n",
    "            'CLE @ NYJ': ('Sunday', '1:00 PM ET'),\n",
    "            'NE @ TB': ('Sunday', '1:00 PM ET'),\n",
    "            'NO @ CAR': ('Sunday', '1:00 PM ET'),\n",
    "            'JAX @ HOU': ('Sunday', '1:00 PM ET'),\n",
    "            'ARI @ SEA': ('Sunday', '4:05 PM ET'),\n",
    "            'LA @ SF': ('Sunday', '4:25 PM ET'),\n",
    "            'DET @ WAS': ('Sunday', '4:25 PM ET'),\n",
    "            'PIT @ LAC': ('Sunday', '8:20 PM ET'),\n",
    "            'PHI @ GB': ('Monday', '8:15 PM ET')\n",
    "        }\n",
    "        \n",
    "        time_order = [\n",
    "            'LV @ DEN',\n",
    "            'ATL @ IND',\n",
    "            'NYG @ CHI', 'BUF @ MIA', 'BAL @ MIN', 'CLE @ NYJ', 'NE @ TB', 'NO @ CAR', 'JAX @ HOU',\n",
    "            'ARI @ SEA', 'LA @ SF', 'DET @ WAS',\n",
    "            'PIT @ LAC',\n",
    "            'PHI @ GB'\n",
    "        ]\n",
    "        \n",
    "        # Team name mapping for display\n",
    "        team_names = {\n",
    "            'WAS': 'Commanders', 'GB': 'Packers', 'NYG': 'Giants', 'DAL': 'Cowboys',\n",
    "            'SEA': 'Seahawks', 'PIT': 'Steelers', 'LA': 'Rams', 'TEN': 'Titans',\n",
    "            'BUF': 'Bills', 'NYJ': 'Jets', 'NE': 'Patriots', 'MIA': 'Dolphins',\n",
    "            'JAX': 'Jaguars', 'CIN': 'Bengals', 'SF': '49ers', 'NO': 'Saints',\n",
    "            'CLE': 'Browns', 'BAL': 'Ravens', 'CHI': 'Bears', 'DET': 'Lions',\n",
    "            'DEN': 'Broncos', 'IND': 'Colts', 'CAR': 'Panthers', 'ARI': 'Cardinals',\n",
    "            'PHI': 'Eagles', 'KC': 'Chiefs', 'ATL': 'Falcons', 'MIN': 'Vikings',\n",
    "            'TB': 'Buccaneers', 'HOU': 'Texans', 'LAC': 'Chargers', 'LV': 'Raiders'\n",
    "        }\n",
    "        \n",
    "        # Display results with spreads\n",
    "        for matchup in time_order:\n",
    "            game_row = week10_spread_results[week10_spread_results['matchup'] == matchup]\n",
    "            if not game_row.empty:\n",
    "                game = game_row.iloc[0]\n",
    "                winner_abbr = game['predicted_winner']\n",
    "                winner_name = team_names.get(winner_abbr, winner_abbr)\n",
    "                spread_display = game['spread_display']\n",
    "                \n",
    "                print(f\"{game['matchup']:<20} {spread_display:<15} {winner_name:<12} {game['confidence']:.1%}\")\n",
    "        \n",
    "        print(\"-\" * 70)\n",
    "        print(f\"Total Games: {len(week10_spread_results)} | Avg Spread: {week10_spread_results['spread_magnitude'].mean():.1f} pts\")\n",
    "        \n",
    "        # Additional insights\n",
    "        close_games = week10_spread_results[week10_spread_results['spread_magnitude'] <= 3.5]\n",
    "        blowouts = week10_spread_results[week10_spread_results['spread_magnitude'] >= 10.0]\n",
    "        print(f\"\\nGAME ANALYSIS:\")\n",
    "        print(f\"  Close games (≤3.5 pts): {len(close_games)}\")\n",
    "        print(f\"  Potential blowouts (≥10 pts): {len(blowouts)}\")\n",
    "        print(f\"  Home teams favored: {(week10_spread_results['predicted_spread'] > 0).sum()}\")\n",
    "        print(f\"  Away teams favored: {(week10_spread_results['predicted_spread'] < 0).sum()}\")\n",
    "\n",
    "        print(f\"\\nResults saved to 'week10_spread_results' variable\")\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Failed to generate spread predictions\")\n",
    "        \n",
    "else:\n",
    "    print(\"ERROR: Models not trained yet!\")\n",
    "    print(\"\\nPlease run:\")\n",
    "    print(\"1. Step 2 to train the winner prediction model\")\n",
    "    print(\"2. Step 8 to train the spread prediction model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12473c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION (Update these for each week) =====\n",
    "WEEK_NUMBER = 10\n",
    "SEASON = 2025\n",
    "\n",
    "# ===== AUTOMATED RESULT FETCHING =====\n",
    "def fetch_actual_results(predictions_df, season, week):\n",
    "    \"\"\"\n",
    "    Automatically fetch actual game results from nfl_data_py\n",
    "    No more manual data entry needed!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to use already-loaded schedule_data if available (faster)\n",
    "        if 'schedule_data' in globals() and schedule_data is not None:\n",
    "            print(f\"Using existing schedule data for {season} Week {week}...\")\n",
    "            current_schedule = schedule_data.copy()\n",
    "            # Filter for the target season\n",
    "            current_schedule = current_schedule[current_schedule['season'] == season]\n",
    "            if not current_schedule.empty:\n",
    "                print(f\"Found {len(current_schedule)} games in existing data for {season}\")\n",
    "            else:\n",
    "                # Fall back to downloading fresh data\n",
    "                print(f\"Existing data doesn't have {season}, downloading fresh data...\")\n",
    "                current_schedule = nfl.import_schedules([season])\n",
    "        else:\n",
    "            # Import fresh schedule data for the target week\n",
    "            print(f\"Fetching schedule data for {season} Week {week}...\")\n",
    "            current_schedule = nfl.import_schedules([season])\n",
    "        \n",
    "        if current_schedule.empty:\n",
    "            print(f\"Warning: No schedule data found for {season}. Trying previous season...\")\n",
    "            # Try previous season as fallback\n",
    "            current_schedule = nfl.import_schedules([season - 1])\n",
    "            if current_schedule.empty:\n",
    "                print(f\"Error: No schedule data available for {season} or {season - 1}\")\n",
    "                return None\n",
    "        \n",
    "        # Filter for the specific week\n",
    "        week_games = current_schedule[\n",
    "            (current_schedule['season'] == season) & \n",
    "            (current_schedule['week'] == week)\n",
    "        ].copy()\n",
    "        \n",
    "        if week_games.empty:\n",
    "            print(f\"Warning: No games found for {season} Week {week}\")\n",
    "            if 'week' in current_schedule.columns:\n",
    "                available_weeks = sorted([w for w in current_schedule['week'].unique() if pd.notna(w)])\n",
    "                print(f\"Available weeks in data: {available_weeks}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Found {len(week_games)} scheduled games for Week {week}\")\n",
    "        \n",
    "        # Ensure team columns are strings for matching\n",
    "        if 'away_team' in week_games.columns:\n",
    "            week_games['away_team'] = week_games['away_team'].astype(str).str.strip()\n",
    "        if 'home_team' in week_games.columns:\n",
    "            week_games['home_team'] = week_games['home_team'].astype(str).str.strip()\n",
    "        \n",
    "        actual_results = {}\n",
    "        games_found = 0\n",
    "        games_played = 0\n",
    "        games_missing = []\n",
    "        \n",
    "        # Process each prediction to find actual results\n",
    "        for _, pred_row in predictions_df.iterrows():\n",
    "            matchup = pred_row['matchup']\n",
    "            away_team = str(pred_row['away_team']).strip().upper()\n",
    "            home_team = str(pred_row['home_team']).strip().upper()\n",
    "            \n",
    "            # Find corresponding game in schedule (case-insensitive matching)\n",
    "            game_row = week_games[\n",
    "                (week_games['away_team'].str.upper() == away_team) & \n",
    "                (week_games['home_team'].str.upper() == home_team)\n",
    "            ]\n",
    "            \n",
    "            if not game_row.empty:\n",
    "                game = game_row.iloc[0]\n",
    "                games_found += 1\n",
    "                \n",
    "                # Use direct column access instead of .get() for pandas Series\n",
    "                try:\n",
    "                    home_score = game['home_score'] if 'home_score' in game.index else None\n",
    "                    away_score = game['away_score'] if 'away_score' in game.index else None\n",
    "                except (KeyError, AttributeError):\n",
    "                    # Fallback to .get() if direct access fails\n",
    "                    home_score = game.get('home_score', None) if hasattr(game, 'get') else None\n",
    "                    away_score = game.get('away_score', None) if hasattr(game, 'get') else None\n",
    "                \n",
    "                # Check if scores are available and valid\n",
    "                if pd.notna(home_score) and pd.notna(away_score):\n",
    "                    try:\n",
    "                        home_score = float(home_score)\n",
    "                        away_score = float(away_score)\n",
    "                        \n",
    "                        # Game completed - extract results\n",
    "                        winner = home_team if home_score > away_score else away_team\n",
    "                        \n",
    "                        # Get additional game info safely\n",
    "                        game_id = game['game_id'] if 'game_id' in game.index else ''\n",
    "                        gameday = game['gameday'] if 'gameday' in game.index else ''\n",
    "                        \n",
    "                        actual_results[matchup] = {\n",
    "                            'winner': winner,\n",
    "                            'home_score': int(home_score),\n",
    "                            'away_score': int(away_score),\n",
    "                            'game_id': game_id,\n",
    "                            'gameday': gameday\n",
    "                        }\n",
    "                        games_played += 1\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        print(f\"Warning: Could not parse scores for {matchup}: {e}\")\n",
    "                        games_missing.append(matchup)\n",
    "                else:\n",
    "                    games_missing.append(matchup)\n",
    "            else:\n",
    "                games_missing.append(matchup)\n",
    "        \n",
    "        print(f\"\\nResults Summary:\")\n",
    "        print(f\"  Games found in schedule: {games_found}/{len(predictions_df)}\")\n",
    "        print(f\"  Games with completed scores: {games_played}/{len(predictions_df)}\")\n",
    "        \n",
    "        if games_missing:\n",
    "            print(f\"\\nGames not yet completed or not found:\")\n",
    "            for gm in games_missing[:5]:  # Show first 5\n",
    "                print(f\"  - {gm}\")\n",
    "            if len(games_missing) > 5:\n",
    "                print(f\"  ... and {len(games_missing) - 5} more\")\n",
    "        \n",
    "        if games_played == 0:\n",
    "            print(f\"\\nNo completed games found for Week {week}, {season}\")\n",
    "            print(\"Games may not have been played yet, or scores are not available.\")\n",
    "            return None\n",
    "            \n",
    "        return actual_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error fetching results: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(\"\\nFull traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def quick_results_check(week_num=None, season_year=None):\n",
    "    \"\"\"\n",
    "    One-click function to check results for any week\n",
    "    \"\"\"\n",
    "    # Use config values if not specified\n",
    "    if week_num is None:\n",
    "        week_num = WEEK_NUMBER\n",
    "    if season_year is None:\n",
    "        season_year = SEASON\n",
    "    \n",
    "    # Find the predictions variable for this week\n",
    "    predictions_var = f'week{week_num}_spread_results'\n",
    "    \n",
    "    if predictions_var in locals() or predictions_var in globals():\n",
    "        try:\n",
    "            # Get the predictions dataframe\n",
    "            if predictions_var in locals():\n",
    "                predictions_df = locals()[predictions_var]\n",
    "            else:\n",
    "                predictions_df = globals()[predictions_var]\n",
    "            \n",
    "            # Fetch actual results automatically\n",
    "            actual_results = fetch_actual_results(predictions_df, season_year, week_num)\n",
    "            \n",
    "            if actual_results:\n",
    "                # Run the analysis with fetched results\n",
    "                results = analyze_week(week_num, season_year, predictions_df, actual_results)\n",
    "                \n",
    "                # Save to global variable\n",
    "                globals()[f'week{week_num}_final_results'] = results\n",
    "                globals()[f'week{week_num}_actual_results'] = actual_results\n",
    "                \n",
    "                return results\n",
    "            else:\n",
    "                print(\"No results available yet - games may not be completed.\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"'{predictions_var}' not found - run predictions first\")\n",
    "        return None\n",
    "\n",
    "# Smart result fetcher - tries auto-fetch, falls back gracefully\n",
    "def get_week_results(predictions_df=None, manual_results=None):\n",
    "    \"\"\"\n",
    "    Smart function that tries automatic fetching first, \n",
    "    then falls back to manual results if provided\n",
    "    \"\"\"\n",
    "    if predictions_df is None:\n",
    "        # Try to find week1_results\n",
    "        if 'week1_results' in locals():\n",
    "            predictions_df = week1_results\n",
    "        elif 'week1_results' in globals():\n",
    "            predictions_df = globals()['week1_results']\n",
    "        else:\n",
    "            print(\"No predictions found. Run predictions first.\")\n",
    "            return None\n",
    "    \n",
    "    # Try automatic fetching first\n",
    "    actual_results = fetch_actual_results(predictions_df, SEASON, WEEK_NUMBER)\n",
    "    \n",
    "    if actual_results:\n",
    "        return actual_results\n",
    "    elif manual_results:\n",
    "        return manual_results\n",
    "    else:\n",
    "        print(\"No results available - games may not be completed yet\")\n",
    "        return None\n",
    "\n",
    "print(\"Result system ready. Use: quick_results_check()\")\n",
    "\n",
    "# ===== AUTOMATED ANALYSIS CODE (No changes needed below) =====\n",
    "\n",
    "def analyze_week(week_num, season_year, predictions_df, actuals):\n",
    "    \"\"\"\n",
    "    Universal function to analyze any week's predictions vs actual results\n",
    "    \"\"\"\n",
    "    print(\"=\" * 95)\n",
    "    print(f\"{' ' * 25}NFL WEEK {week_num} {season_year} - FINAL RESULTS\")\n",
    "    print(\"=\" * 95)\n",
    "    \n",
    "    # Build comparison\n",
    "    results = {}\n",
    "    for matchup, actual in actuals.items():\n",
    "        pred_row = predictions_df[predictions_df['matchup'] == matchup]\n",
    "        if not pred_row.empty:\n",
    "            pred = pred_row.iloc[0]['predicted_winner']\n",
    "            conf = pred_row.iloc[0]['confidence'] * 100\n",
    "            results[matchup] = {\n",
    "                'predicted': pred,\n",
    "                'actual': actual['winner'],\n",
    "                'score': f\"{actual['away_score']}-{actual['home_score']}\",\n",
    "                'correct': pred == actual['winner'],\n",
    "                'confidence': conf\n",
    "            }\n",
    "    \n",
    "    # Display table\n",
    "    print(f\"\\n{'GAME':<20} {'PREDICTED':<12} {'ACTUAL':<12} {'SCORE':<12} {'RESULT':<10}\")\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    correct = sum(1 for r in results.values() if r['correct'])\n",
    "    total = len(results)\n",
    "    \n",
    "    for matchup, result in results.items():\n",
    "        status = \"CORRECT\" if result['correct'] else \"WRONG\"\n",
    "        print(f\"{matchup:<20} {result['predicted']:<12} {result['actual']:<12} {result['score']:<12} {status:<10}\")\n",
    "    \n",
    "    # Summary\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    print(\"-\" * 95)\n",
    "    print(f\"\\nOVERALL ACCURACY: {correct}/{total} = {accuracy:.1f}%\\n\")\n",
    "    \n",
    "    # Breakdown\n",
    "    correct_games = [(m, r) for m, r in results.items() if r['correct']]\n",
    "    incorrect_games = [(m, r) for m, r in results.items() if not r['correct']]\n",
    "    \n",
    "    print(\"=\" * 95)\n",
    "    print(f\"CORRECT PREDICTIONS ({len(correct_games)}/{total}):\")\n",
    "    print(\"=\" * 95)\n",
    "    for matchup, result in correct_games:\n",
    "        print(f\"  {matchup:<20} {result['actual']:<5} | Score: {result['score']:<10} | Confidence: {result['confidence']:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 95)\n",
    "    print(f\"INCORRECT PREDICTIONS ({len(incorrect_games)}/{total}):\")\n",
    "    print(\"=\" * 95)\n",
    "    for matchup, result in incorrect_games:\n",
    "        print(f\"  {matchup:<20} Predicted: {result['predicted']:<5} | Actual: {result['actual']:<5} | Score: {result['score']}\")\n",
    "    \n",
    "    # High confidence analysis\n",
    "    high_conf = {m: r for m, r in results.items() if r['confidence'] > 65}\n",
    "    if high_conf:\n",
    "        hc_correct = sum(1 for r in high_conf.values() if r['correct'])\n",
    "        hc_accuracy = (hc_correct / len(high_conf) * 100)\n",
    "        print(\"\\n\" + \"=\" * 95)\n",
    "        print(f\"HIGH CONFIDENCE PICKS (>65%): {hc_correct}/{len(high_conf)} = {hc_accuracy:.1f}%\")\n",
    "        print(\"=\" * 95)\n",
    "        for matchup, result in high_conf.items():\n",
    "            status = \"✓\" if result['correct'] else \"✗\"\n",
    "            print(f\"{status} {matchup:<20} {result['predicted']:<5} ({result['confidence']:.1f}%) → Actual: {result['actual']}\")\n",
    "    \n",
    "    print(f\"\\nResults saved to 'week{week_num}_final_results'\")\n",
    "    return results\n",
    "\n",
    "# ===== SEAMLESS EXECUTION =====\n",
    "# Auto-run analysis if predictions exist\n",
    "if f'week{WEEK_NUMBER}_spread_results' in globals():\n",
    "    quick_results_check()\n",
    "else:\n",
    "    print(\"Run predictions first, then return here for results analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Week 10 predictions to CSV for Plot.ipynb\n",
    "# This allows Plot.ipynb to load predictions even in different Jupyter sessions\n",
    "\n",
    "if 'week10_spread_results' in globals() and week10_spread_results is not None:\n",
    "    import os\n",
    "    # Save in the Week10 directory so Plot.ipynb can find it\n",
    "    csv_path = os.path.join(\"week10_predictions.csv\")\n",
    "    week10_spread_results.to_csv(csv_path, index=False)\n",
    "    print(f\"✓ Saved Week 10 predictions to {os.path.abspath(csv_path)}\")\n",
    "    print(f\"  Total predictions: {len(week10_spread_results)}\")\n",
    "    print(f\"  This file can now be loaded by Plot.ipynb automatically!\")\n",
    "else:\n",
    "    print(\"⚠ week10_spread_results not found. Run the prediction cell first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

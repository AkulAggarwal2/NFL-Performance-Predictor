{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10+ Enhancement Debug: Ablation Study\n",
    "\n",
    "**Objective**: Systematically test each Week 10+ enhancement on 2024 holdout data to identify which features hurt performance.\n",
    "\n",
    "**Baseline**: Week 9 legacy model (expected ~60% on 2024)\n",
    "\n",
    "**Enhancements to Test**:\n",
    "1. Temporal Weighting: exp(-0.15 √ó years_ago)\n",
    "2. Momentum Features: momentum_last3, momentum_advantage\n",
    "3. Vegas Spread: vegas_spread feature\n",
    "4. Injury Estimates: injury_pct calculations\n",
    "5. Defensive Stats: defensive_ypg, defensive_ppg\n",
    "6. 4th Model (GB): Gradient Boosting Classifier\n",
    "7. Increased Depths: RF 5‚Üí15, XGB 5‚Üí8\n",
    "8. Full Week 10: All enhancements together\n",
    "\n",
    "**Success Criteria**: Identify which specific features caused -7.7% accuracy drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q xgboost nfl_data_py scikit-learn pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nfl_data_py as nfl\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss, roc_auc_score, classification_report\n",
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 2024 Holdout Data\n",
    "\n",
    "We'll test all configurations on the full 2024 season (Weeks 1-18) using walk-forward validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NFL data for ablation study...\n",
      "This may take 5-10 minutes on first run...\n",
      "\n",
      "Downloading play-by-play data (2015-2024)...\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "2024 done.\n",
      "Downcasting floats.\n",
      "  Loaded 483,605 plays\n",
      "\n",
      "Downloading weekly player statistics...\n",
      "Downcasting floats.\n",
      "  Loaded 54,479 player-game records\n",
      "\n",
      "Downloading schedule data...\n",
      "  Loaded 2,743 scheduled games\n",
      "\n",
      "‚úÖ Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading NFL data for ablation study...\")\n",
    "print(\"This may take 5-10 minutes on first run...\\n\")\n",
    "\n",
    "# Load data 2015-2024 for training/testing\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2024\n",
    "TEST_YEAR = 2024\n",
    "\n",
    "# Load play-by-play, weekly stats, and schedule\n",
    "print(f\"Downloading play-by-play data ({START_YEAR}-{END_YEAR})...\")\n",
    "pbp_data = nfl.import_pbp_data(years=range(START_YEAR, END_YEAR + 1))\n",
    "print(f\"  Loaded {len(pbp_data):,} plays\")\n",
    "\n",
    "print(f\"\\nDownloading weekly player statistics...\")\n",
    "weekly_data = nfl.import_weekly_data(years=range(START_YEAR, END_YEAR + 1))\n",
    "print(f\"  Loaded {len(weekly_data):,} player-game records\")\n",
    "\n",
    "print(f\"\\nDownloading schedule data...\")\n",
    "schedule_data = nfl.import_schedules(years=range(START_YEAR, END_YEAR + 1))\n",
    "print(f\"  Loaded {len(schedule_data):,} scheduled games\")\n",
    "\n",
    "print(\"\\n‚úÖ Data loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Feature Engineering Functions\n",
    "\n",
    "We'll create modular functions for each feature type so we can enable/disable them individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering functions created\n"
     ]
    }
   ],
   "source": [
    "def create_team_features_legacy(weekly_data, team, season, week):\n",
    "    \"\"\"\n",
    "    Legacy Week 9 feature engineering (baseline).\n",
    "    Simple season-to-date averages, no momentum or injuries.\n",
    "    \"\"\"\n",
    "    team_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    if team_stats.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Basic offensive stats\n",
    "    features = {\n",
    "        'passing_ypg': team_stats['passing_yards'].sum() / len(team_stats['week'].unique()) if not team_stats.empty else 0,\n",
    "        'rushing_ypg': team_stats['rushing_yards'].sum() / len(team_stats['week'].unique()) if not team_stats.empty else 0,\n",
    "        'total_ypg': (team_stats['passing_yards'].sum() + team_stats['rushing_yards'].sum()) / len(team_stats['week'].unique()) if not team_stats.empty else 0,\n",
    "        'points_pg': team_stats.groupby('week')['fantasy_points'].sum().mean() if not team_stats.empty else 0,\n",
    "        'passing_tds_pg': team_stats['passing_tds'].sum() / len(team_stats['week'].unique()) if not team_stats.empty else 0,\n",
    "        'turnovers_pg': (team_stats['interceptions'].sum() + team_stats.get('fumbles_lost', pd.Series([0])).sum()) / len(team_stats['week'].unique()) if not team_stats.empty else 0,\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def add_momentum_features(features, weekly_data, team, season, week):\n",
    "    \"\"\"\n",
    "    Add momentum features (last 3 games win %).\n",
    "    Week 10+ enhancement.\n",
    "    \"\"\"\n",
    "    # This is a simplified version - full implementation would query schedule_data\n",
    "    # For ablation study, we'll estimate from performance variance\n",
    "    team_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    if len(team_stats) >= 3:\n",
    "        last_3_weeks = sorted(team_stats['week'].unique())[-3:]\n",
    "        last_3_stats = team_stats[team_stats['week'].isin(last_3_weeks)]\n",
    "        # Approximate win rate from points scored vs allowed\n",
    "        features['momentum_last3'] = last_3_stats.groupby('week')['fantasy_points'].sum().mean() / 30.0\n",
    "    else:\n",
    "        features['momentum_last3'] = 0.5\n",
    "    \n",
    "    return features\n",
    "\n",
    "def add_injury_features(features, weekly_data, team, season, week):\n",
    "    \"\"\"\n",
    "    Add injury percentage estimates (from performance variance).\n",
    "    Week 10+ enhancement - CIRCULAR LOGIC.\n",
    "    \"\"\"\n",
    "    team_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    if len(team_stats) > 0:\n",
    "        # Estimate injury impact from variance\n",
    "        passing_std = team_stats.groupby('week')['passing_yards'].sum().std()\n",
    "        rushing_std = team_stats.groupby('week')['rushing_yards'].sum().std()\n",
    "        features['injury_pct'] = min(0.3, (passing_std + rushing_std) / 1000.0)\n",
    "    else:\n",
    "        features['injury_pct'] = 0.15\n",
    "    \n",
    "    return features\n",
    "\n",
    "def add_defensive_features(features, pbp_data, team, season, week):\n",
    "    \"\"\"\n",
    "    Add defensive stats (yards/points allowed).\n",
    "    Week 10+ enhancement - POTENTIALLY HELPFUL.\n",
    "    \"\"\"\n",
    "    defensive_plays = pbp_data[\n",
    "        (pbp_data['defteam'] == team) &\n",
    "        (pbp_data['season'] == season) &\n",
    "        (pbp_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    if len(defensive_plays) > 0:\n",
    "        weeks = defensive_plays['week'].nunique()\n",
    "        features['defensive_ypg'] = defensive_plays['yards_gained'].sum() / weeks if weeks > 0 else 0\n",
    "        # Estimate points allowed from EPA\n",
    "        features['defensive_ppg'] = defensive_plays['epa'].sum() * 6 / weeks if weeks > 0 else 0\n",
    "    else:\n",
    "        features['defensive_ypg'] = 0\n",
    "        features['defensive_ppg'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"‚úÖ Feature engineering functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Configurable Model Class\n",
    "\n",
    "This class allows us to enable/disable specific features for ablation testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ConfigurablePredictor class created\n"
     ]
    }
   ],
   "source": [
    "class ConfigurablePredictor:\n",
    "    \"\"\"\n",
    "    NFL predictor with configurable features for ablation study.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config: dict with feature flags\n",
    "                {\n",
    "                    'use_momentum': False,\n",
    "                    'use_injuries': False,\n",
    "                    'use_defensive': False,\n",
    "                    'use_vegas': False,\n",
    "                    'temporal_weighting': False,\n",
    "                    'use_4th_model': False,\n",
    "                    'tree_max_depth': 5,\n",
    "                    'n_features': 10\n",
    "                }\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.feature_names = []\n",
    "    \n",
    "    def build_features(self, pbp_data, weekly_data, schedule_data, season, week):\n",
    "        \"\"\"\n",
    "        Build feature matrix for a specific season/week.\n",
    "        \"\"\"\n",
    "        games = schedule_data[\n",
    "            (schedule_data['season'] == season) &\n",
    "            (schedule_data['week'] == week)\n",
    "        ]\n",
    "        \n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        for _, game in games.iterrows():\n",
    "            home_team = game['home_team']\n",
    "            away_team = game['away_team']\n",
    "            \n",
    "            # Legacy features\n",
    "            home_features = create_team_features_legacy(weekly_data, home_team, season, week)\n",
    "            away_features = create_team_features_legacy(weekly_data, away_team, season, week)\n",
    "            \n",
    "            if not home_features or not away_features:\n",
    "                continue\n",
    "            \n",
    "            # Add momentum if enabled\n",
    "            if self.config.get('use_momentum', False):\n",
    "                home_features = add_momentum_features(home_features, weekly_data, home_team, season, week)\n",
    "                away_features = add_momentum_features(away_features, weekly_data, away_team, season, week)\n",
    "            \n",
    "            # Add injuries if enabled\n",
    "            if self.config.get('use_injuries', False):\n",
    "                home_features = add_injury_features(home_features, weekly_data, home_team, season, week)\n",
    "                away_features = add_injury_features(away_features, weekly_data, away_team, season, week)\n",
    "            \n",
    "            # Add defensive if enabled\n",
    "            if self.config.get('use_defensive', False):\n",
    "                home_features = add_defensive_features(home_features, pbp_data, home_team, season, week)\n",
    "                away_features = add_defensive_features(away_features, pbp_data, away_team, season, week)\n",
    "            \n",
    "            # Combine features\n",
    "            combined = {}\n",
    "            for key in home_features.keys():\n",
    "                combined[f'home_{key}'] = home_features[key]\n",
    "                combined[f'away_{key}'] = away_features.get(key, 0)\n",
    "            \n",
    "            # Add advantage features\n",
    "            combined['scoring_advantage'] = home_features.get('points_pg', 0) - away_features.get('points_pg', 0)\n",
    "            combined['turnover_advantage'] = away_features.get('turnovers_pg', 0) - home_features.get('turnovers_pg', 0)\n",
    "            \n",
    "            if self.config.get('use_momentum', False):\n",
    "                combined['momentum_advantage'] = home_features.get('momentum_last3', 0.5) - away_features.get('momentum_last3', 0.5)\n",
    "            \n",
    "            # Contextual\n",
    "            combined['is_playoff'] = 1 if week >= 18 else 0\n",
    "            combined['season'] = season\n",
    "            \n",
    "            # Vegas spread (if enabled) - PLACEHOLDER (would need external data)\n",
    "            if self.config.get('use_vegas', False):\n",
    "                combined['vegas_spread'] = 0  # Placeholder\n",
    "            \n",
    "            X_list.append(combined)\n",
    "            \n",
    "            # Target: home team win\n",
    "            if pd.notna(game.get('home_score')) and pd.notna(game.get('away_score')):\n",
    "                y_list.append(1 if game['home_score'] > game['away_score'] else 0)\n",
    "            else:\n",
    "                y_list.append(None)\n",
    "        \n",
    "        X = pd.DataFrame(X_list)\n",
    "        y = pd.Series(y_list)\n",
    "        \n",
    "        # Remove rows with missing labels\n",
    "        valid_mask = y.notna()\n",
    "        X = X[valid_mask]\n",
    "        y = y[valid_mask]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Train ensemble model with configured architecture.\n",
    "        \"\"\"\n",
    "        depth = self.config.get('tree_max_depth', 5)\n",
    "        use_4th = self.config.get('use_4th_model', False)\n",
    "        \n",
    "        # Build ensemble\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=depth, random_state=42)\n",
    "        lr = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "        xgb_model = xgb.XGBClassifier(max_depth=depth, learning_rate=0.1, n_estimators=200, random_state=42)\n",
    "        \n",
    "        if use_4th:\n",
    "            gb = GradientBoostingClassifier(max_depth=8, learning_rate=0.1, n_estimators=200, random_state=42)\n",
    "            estimators = [('rf', rf), ('lr', lr), ('xgb', xgb_model), ('gb', gb)]\n",
    "        else:\n",
    "            estimators = [('rf', rf), ('lr', lr), ('xgb', xgb_model)]\n",
    "        \n",
    "        voting = VotingClassifier(estimators=estimators, voting='soft')\n",
    "        \n",
    "        # Calibrate\n",
    "        self.model = CalibratedClassifierCV(voting, method='isotonic', cv=3)\n",
    "        \n",
    "        # Apply temporal weighting if enabled\n",
    "        if self.config.get('temporal_weighting', False):\n",
    "            current_year = X_train['season'].max()\n",
    "            years_ago = current_year - X_train['season']\n",
    "            weights = np.exp(-0.15 * years_ago)\n",
    "            self.model.fit(X_train, y_train, sample_weight=weights)\n",
    "        else:\n",
    "            self.model.fit(X_train, y_train)\n",
    "        \n",
    "        self.feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Generate predictions.\n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        return y_pred, y_proba\n",
    "\n",
    "print(\"‚úÖ ConfigurablePredictor class created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation Study: Test Each Enhancement\n",
    "\n",
    "We'll test 8 configurations on 2024 data using walk-forward validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ablation test function ready\n"
     ]
    }
   ],
   "source": [
    "def run_ablation_test(config_name, config, pbp_data, weekly_data, schedule_data):\n",
    "    \"\"\"\n",
    "    Run single ablation test on 2024 data.\n",
    "    \n",
    "    Returns:\n",
    "        dict with accuracy, HC accuracy, brier score, AUC\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Testing: {config_name}\")\n",
    "    print(f\"Config: {config}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    predictor = ConfigurablePredictor(config)\n",
    "    \n",
    "    # Walk-forward validation on 2024\n",
    "    all_preds = []\n",
    "    all_actuals = []\n",
    "    all_probas = []\n",
    "    \n",
    "    for test_week in range(1, 19):  # Weeks 1-18\n",
    "        print(f\"  Testing week {test_week}...\", end=\" \")\n",
    "        \n",
    "        # Train on 2015-2023 + 2024 weeks 1 to test_week-1\n",
    "        X_train_list = []\n",
    "        y_train_list = []\n",
    "        \n",
    "        # Historical data (2015-2023)\n",
    "        for train_year in range(2015, 2024):\n",
    "            for train_week in range(1, 19):\n",
    "                X_week, y_week = predictor.build_features(pbp_data, weekly_data, schedule_data, train_year, train_week)\n",
    "                if len(X_week) > 0:\n",
    "                    X_train_list.append(X_week)\n",
    "                    y_train_list.append(y_week)\n",
    "        \n",
    "        # 2024 data up to test_week-1\n",
    "        for train_week in range(1, test_week):\n",
    "            X_week, y_week = predictor.build_features(pbp_data, weekly_data, schedule_data, 2024, train_week)\n",
    "            if len(X_week) > 0:\n",
    "                X_train_list.append(X_week)\n",
    "                y_train_list.append(y_week)\n",
    "        \n",
    "        if len(X_train_list) == 0:\n",
    "            print(\"No training data\")\n",
    "            continue\n",
    "        \n",
    "        X_train = pd.concat(X_train_list, ignore_index=True)\n",
    "        y_train = pd.concat(y_train_list, ignore_index=True)\n",
    "        \n",
    "        # Test on current week\n",
    "        X_test, y_test = predictor.build_features(pbp_data, weekly_data, schedule_data, 2024, test_week)\n",
    "        \n",
    "        if len(X_test) == 0:\n",
    "            print(\"No test data\")\n",
    "            continue\n",
    "        \n",
    "        # Train and predict\n",
    "        predictor.train(X_train, y_train)\n",
    "        y_pred, y_proba = predictor.predict(X_test)\n",
    "        \n",
    "        all_preds.extend(y_pred)\n",
    "        all_actuals.extend(y_test)\n",
    "        all_probas.extend(y_proba)\n",
    "        \n",
    "        week_acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Acc: {week_acc:.1%}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_actuals, all_preds)\n",
    "    brier = brier_score_loss(all_actuals, all_probas)\n",
    "    auc = roc_auc_score(all_actuals, all_probas)\n",
    "    \n",
    "    # High-confidence accuracy (>70%)\n",
    "    hc_mask = np.array([(p > 0.70 or p < 0.30) for p in all_probas])\n",
    "    if hc_mask.sum() > 0:\n",
    "        hc_preds = np.array(all_preds)[hc_mask]\n",
    "        hc_actuals = np.array(all_actuals)[hc_mask]\n",
    "        hc_accuracy = accuracy_score(hc_actuals, hc_preds)\n",
    "    else:\n",
    "        hc_accuracy = None\n",
    "    \n",
    "    results = {\n",
    "        'config_name': config_name,\n",
    "        'accuracy': accuracy,\n",
    "        'hc_accuracy': hc_accuracy,\n",
    "        'brier_score': brier,\n",
    "        'auc_roc': auc,\n",
    "        'n_games': len(all_actuals),\n",
    "        'n_hc_games': hc_mask.sum() if hc_mask.sum() > 0 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä RESULTS: {config_name}\")\n",
    "    print(f\"  Accuracy: {accuracy:.1%}\")\n",
    "    print(f\"  HC Accuracy: {hc_accuracy:.1%}\" if hc_accuracy else \"  HC Accuracy: N/A\")\n",
    "    print(f\"  Brier Score: {brier:.3f}\")\n",
    "    print(f\"  AUC-ROC: {auc:.3f}\")\n",
    "    print(f\"  Games: {len(all_actuals)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Ablation test function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All 8 Ablation Tests\n",
    "\n",
    "**WARNING**: This will take 2-4 hours to complete all tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING ABLATION STUDY\n",
      "Testing 8 configurations on 2024 holdout data\n",
      "Expected duration: 2-4 hours\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Testing: 1. BASELINE (Week 9 Legacy)\n",
      "Config: {'use_momentum': False, 'use_injuries': False, 'use_defensive': False, 'use_vegas': False, 'temporal_weighting': False, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 56.2%\n",
      "  Testing week 3... Acc: 50.0%\n",
      "  Testing week 4... Acc: 62.5%\n",
      "  Testing week 5... Acc: 64.3%\n",
      "  Testing week 6... Acc: 57.1%\n",
      "  Testing week 7... Acc: 86.7%\n",
      "  Testing week 8... Acc: 62.5%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 64.3%\n",
      "  Testing week 11... Acc: 57.1%\n",
      "  Testing week 12... Acc: 76.9%\n",
      "  Testing week 13... Acc: 56.2%\n",
      "  Testing week 14... Acc: 84.6%\n",
      "  Testing week 15... Acc: 87.5%\n",
      "  Testing week 16... Acc: 75.0%\n",
      "  Testing week 17... Acc: 68.8%\n",
      "  Testing week 18... Acc: 62.5%\n",
      "\n",
      "üìä RESULTS: 1. BASELINE (Week 9 Legacy)\n",
      "  Accuracy: 66.8%\n",
      "  HC Accuracy: 73.3%\n",
      "  Brier Score: 0.221\n",
      "  AUC-ROC: 0.718\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 2. Baseline + Temporal Weighting\n",
      "Config: {'use_momentum': False, 'use_injuries': False, 'use_defensive': False, 'use_vegas': False, 'temporal_weighting': True, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 50.0%\n",
      "  Testing week 3... Acc: 56.2%\n",
      "  Testing week 4... Acc: 56.2%\n",
      "  Testing week 5... Acc: 50.0%\n",
      "  Testing week 6... Acc: 78.6%\n",
      "  Testing week 7... Acc: 73.3%\n",
      "  Testing week 8... Acc: 62.5%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 64.3%\n",
      "  Testing week 11... Acc: 57.1%\n",
      "  Testing week 12... Acc: 69.2%\n",
      "  Testing week 13... Acc: 75.0%\n",
      "  Testing week 14... Acc: 76.9%\n",
      "  Testing week 15... Acc: 87.5%\n",
      "  Testing week 16... Acc: 68.8%\n",
      "  Testing week 17... Acc: 75.0%\n",
      "  Testing week 18... Acc: 75.0%\n",
      "\n",
      "üìä RESULTS: 2. Baseline + Temporal Weighting\n",
      "  Accuracy: 67.2%\n",
      "  HC Accuracy: 76.0%\n",
      "  Brier Score: 0.221\n",
      "  AUC-ROC: 0.715\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 3. Baseline + Momentum Features\n",
      "Config: {'use_momentum': True, 'use_injuries': False, 'use_defensive': False, 'use_vegas': False, 'temporal_weighting': False, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 50.0%\n",
      "  Testing week 3... Acc: 50.0%\n",
      "  Testing week 4... Acc: 50.0%\n",
      "  Testing week 5... Acc: 50.0%\n",
      "  Testing week 6... Acc: 78.6%\n",
      "  Testing week 7... Acc: 80.0%\n",
      "  Testing week 8... Acc: 56.2%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 71.4%\n",
      "  Testing week 11... Acc: 64.3%\n",
      "  Testing week 12... Acc: 76.9%\n",
      "  Testing week 13... Acc: 75.0%\n",
      "  Testing week 14... Acc: 69.2%\n",
      "  Testing week 15... Acc: 93.8%\n",
      "  Testing week 16... Acc: 81.2%\n",
      "  Testing week 17... Acc: 68.8%\n",
      "  Testing week 18... Acc: 68.8%\n",
      "\n",
      "üìä RESULTS: 3. Baseline + Momentum Features\n",
      "  Accuracy: 67.6%\n",
      "  HC Accuracy: 92.3%\n",
      "  Brier Score: 0.221\n",
      "  AUC-ROC: 0.724\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 4. Baseline + Vegas Spread\n",
      "Config: {'use_momentum': False, 'use_injuries': False, 'use_defensive': False, 'use_vegas': True, 'temporal_weighting': False, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 56.2%\n",
      "  Testing week 3... Acc: 50.0%\n",
      "  Testing week 4... Acc: 62.5%\n",
      "  Testing week 5... Acc: 64.3%\n",
      "  Testing week 6... Acc: 71.4%\n",
      "  Testing week 7... Acc: 86.7%\n",
      "  Testing week 8... Acc: 75.0%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 64.3%\n",
      "  Testing week 11... Acc: 57.1%\n",
      "  Testing week 12... Acc: 76.9%\n",
      "  Testing week 13... Acc: 56.2%\n",
      "  Testing week 14... Acc: 76.9%\n",
      "  Testing week 15... Acc: 87.5%\n",
      "  Testing week 16... Acc: 75.0%\n",
      "  Testing week 17... Acc: 68.8%\n",
      "  Testing week 18... Acc: 62.5%\n",
      "\n",
      "üìä RESULTS: 4. Baseline + Vegas Spread\n",
      "  Accuracy: 68.0%\n",
      "  HC Accuracy: 86.7%\n",
      "  Brier Score: 0.222\n",
      "  AUC-ROC: 0.715\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 5. Baseline + Injury Estimates\n",
      "Config: {'use_momentum': False, 'use_injuries': True, 'use_defensive': False, 'use_vegas': False, 'temporal_weighting': False, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 56.2%\n",
      "  Testing week 3... Acc: 50.0%\n",
      "  Testing week 4... Acc: 50.0%\n",
      "  Testing week 5... Acc: 42.9%\n",
      "  Testing week 6... Acc: 57.1%\n",
      "  Testing week 7... Acc: 80.0%\n",
      "  Testing week 8... Acc: 62.5%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 64.3%\n",
      "  Testing week 11... Acc: 50.0%\n",
      "  Testing week 12... Acc: 69.2%\n",
      "  Testing week 13... Acc: 68.8%\n",
      "  Testing week 14... Acc: 69.2%\n",
      "  Testing week 15... Acc: 87.5%\n",
      "  Testing week 16... Acc: 62.5%\n",
      "  Testing week 17... Acc: 81.2%\n",
      "  Testing week 18... Acc: 62.5%\n",
      "\n",
      "üìä RESULTS: 5. Baseline + Injury Estimates\n",
      "  Accuracy: 63.7%\n",
      "  HC Accuracy: 82.4%\n",
      "  Brier Score: 0.224\n",
      "  AUC-ROC: 0.702\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 6. Baseline + Defensive Stats\n",
      "Config: {'use_momentum': False, 'use_injuries': False, 'use_defensive': True, 'use_vegas': False, 'temporal_weighting': False, 'use_4th_model': False, 'tree_max_depth': 5}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 43.8%\n",
      "  Testing week 3... Acc: 50.0%\n",
      "  Testing week 4... Acc: 50.0%\n",
      "  Testing week 5... Acc: 57.1%\n",
      "  Testing week 6... Acc: 57.1%\n",
      "  Testing week 7... Acc: 66.7%\n",
      "  Testing week 8... Acc: 62.5%\n",
      "  Testing week 9... Acc: 66.7%\n",
      "  Testing week 10... Acc: 64.3%\n",
      "  Testing week 11... Acc: 50.0%\n",
      "  Testing week 12... Acc: 76.9%\n",
      "  Testing week 13... Acc: 68.8%\n",
      "  Testing week 14... Acc: 61.5%\n",
      "  Testing week 15... Acc: 81.2%\n",
      "  Testing week 16... Acc: 81.2%\n",
      "  Testing week 17... Acc: 68.8%\n",
      "  Testing week 18... Acc: 62.5%\n",
      "\n",
      "üìä RESULTS: 6. Baseline + Defensive Stats\n",
      "  Accuracy: 62.9%\n",
      "  HC Accuracy: 83.3%\n",
      "  Brier Score: 0.223\n",
      "  AUC-ROC: 0.701\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 7. Baseline + Increased Depth + 4th Model\n",
      "Config: {'use_momentum': False, 'use_injuries': False, 'use_defensive': False, 'use_vegas': False, 'temporal_weighting': False, 'use_4th_model': True, 'tree_max_depth': 15}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 50.0%\n",
      "  Testing week 3... Acc: 37.5%\n",
      "  Testing week 4... Acc: 62.5%\n",
      "  Testing week 5... Acc: 50.0%\n",
      "  Testing week 6... Acc: 64.3%\n",
      "  Testing week 7... Acc: 73.3%\n",
      "  Testing week 8... Acc: 62.5%\n",
      "  Testing week 9... Acc: 60.0%\n",
      "  Testing week 10... Acc: 71.4%\n",
      "  Testing week 11... Acc: 57.1%\n",
      "  Testing week 12... Acc: 53.8%\n",
      "  Testing week 13... Acc: 68.8%\n",
      "  Testing week 14... Acc: 61.5%\n",
      "  Testing week 15... Acc: 93.8%\n",
      "  Testing week 16... Acc: 68.8%\n",
      "  Testing week 17... Acc: 68.8%\n",
      "  Testing week 18... Acc: 62.5%\n",
      "\n",
      "üìä RESULTS: 7. Baseline + Increased Depth + 4th Model\n",
      "  Accuracy: 62.9%\n",
      "  HC Accuracy: 80.8%\n",
      "  Brier Score: 0.225\n",
      "  AUC-ROC: 0.700\n",
      "  Games: 256\n",
      "\n",
      "======================================================================\n",
      "Testing: 8. FULL WEEK 10+ (All Enhancements)\n",
      "Config: {'use_momentum': True, 'use_injuries': True, 'use_defensive': True, 'use_vegas': True, 'temporal_weighting': True, 'use_4th_model': True, 'tree_max_depth': 15}\n",
      "======================================================================\n",
      "  Testing week 1... No test data\n",
      "  Testing week 2... Acc: 50.0%\n",
      "  Testing week 3... Acc: 43.8%\n",
      "  Testing week 4... Acc: 62.5%\n",
      "  Testing week 5... Acc: 57.1%\n",
      "  Testing week 6... Acc: 71.4%\n",
      "  Testing week 7... Acc: 53.3%\n",
      "  Testing week 8... Acc: 75.0%\n",
      "  Testing week 9... Acc: 60.0%\n",
      "  Testing week 10... Acc: 57.1%\n",
      "  Testing week 11... Acc: 57.1%\n",
      "  Testing week 12... Acc: 76.9%\n",
      "  Testing week 13... Acc: 75.0%\n",
      "  Testing week 14... Acc: 76.9%\n",
      "  Testing week 15... Acc: 93.8%\n",
      "  Testing week 16... Acc: 68.8%\n",
      "  Testing week 17... Acc: 75.0%\n",
      "  Testing week 18... Acc: 56.2%\n",
      "\n",
      "üìä RESULTS: 8. FULL WEEK 10+ (All Enhancements)\n",
      "  Accuracy: 65.2%\n",
      "  HC Accuracy: 85.7%\n",
      "  Brier Score: 0.219\n",
      "  AUC-ROC: 0.717\n",
      "  Games: 256\n",
      "\n",
      "‚úÖ ABLATION STUDY COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Define test configurations\n",
    "test_configs = [\n",
    "    (\n",
    "        \"1. BASELINE (Week 9 Legacy)\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"2. Baseline + Temporal Weighting\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': True,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"3. Baseline + Momentum Features\",\n",
    "        {\n",
    "            'use_momentum': True,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"4. Baseline + Vegas Spread\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': True,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"5. Baseline + Injury Estimates\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': True,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"6. Baseline + Defensive Stats\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': True,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': False,\n",
    "            'tree_max_depth': 5,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"7. Baseline + Increased Depth + 4th Model\",\n",
    "        {\n",
    "            'use_momentum': False,\n",
    "            'use_injuries': False,\n",
    "            'use_defensive': False,\n",
    "            'use_vegas': False,\n",
    "            'temporal_weighting': False,\n",
    "            'use_4th_model': True,\n",
    "            'tree_max_depth': 15,\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"8. FULL WEEK 10+ (All Enhancements)\",\n",
    "        {\n",
    "            'use_momentum': True,\n",
    "            'use_injuries': True,\n",
    "            'use_defensive': True,\n",
    "            'use_vegas': True,\n",
    "            'temporal_weighting': True,\n",
    "            'use_4th_model': True,\n",
    "            'tree_max_depth': 15,\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING ABLATION STUDY\")\n",
    "print(\"Testing 8 configurations on 2024 holdout data\")\n",
    "print(\"Expected duration: 2-4 hours\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run all tests\n",
    "ablation_results = []\n",
    "\n",
    "for config_name, config in test_configs:\n",
    "    result = run_ablation_test(config_name, config, pbp_data, weekly_data, schedule_data)\n",
    "    ablation_results.append(result)\n",
    "\n",
    "print(\"\\n‚úÖ ABLATION STUDY COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "ABLATION STUDY RESULTS - 2024 HOLDOUT\n",
      "==========================================================================================\n",
      "\n",
      "CONFIGURATION                                 ACCURACY     DELTA        HC_ACC       BRIER     \n",
      "------------------------------------------------------------------------------------------\n",
      "4. Baseline + Vegas Spread                         68.0%      +1.2%      86.7%     0.222\n",
      "3. Baseline + Momentum Features                    67.6%      +0.8%      92.3%     0.221\n",
      "2. Baseline + Temporal Weighting                   67.2%      +0.4%      76.0%     0.221\n",
      "1. BASELINE (Week 9 Legacy)                        66.8%      +0.0%      73.3%     0.221\n",
      "8. FULL WEEK 10+ (All Enhancements)                65.2%      -1.6%      85.7%     0.219\n",
      "5. Baseline + Injury Estimates                     63.7%      -3.1%      82.4%     0.224\n",
      "6. Baseline + Defensive Stats                      62.9%      -3.9%      83.3%     0.223\n",
      "7. Baseline + Increased Depth + 4th Model          62.9%      -3.9%      80.8%     0.225\n",
      "\n",
      "==========================================================================================\n",
      "KEY FINDINGS\n",
      "==========================================================================================\n",
      "\n",
      "üèÜ BEST: 4. Baseline + Vegas Spread\n",
      "   Accuracy: 68.0% (+1.2% vs baseline)\n",
      "   HC Accuracy: 86.7%\n",
      "\n",
      "‚ùå WORST: 7. Baseline + Increased Depth + 4th Model\n",
      "   Accuracy: 62.9% (-3.9% vs baseline)\n",
      "\n",
      "üìä FEATURE IMPACT ANALYSIS:\n",
      "   Baseline (Week 9 Legacy): 66.8%\n",
      "   Baseline + Momentum Features: +0.8% - NEUTRAL\n",
      "   Baseline + Temporal Weighting: +0.4% - NEUTRAL\n",
      "   BASELINE (Week 9 Legacy): +0.0% - NEUTRAL\n",
      "   FULL WEEK 10+ (All Enhancements): -1.6% - HARMFUL\n",
      "   Baseline + Injury Estimates: -3.1% - HARMFUL\n",
      "   Baseline + Defensive Stats: -3.9% - HARMFUL\n",
      "   Baseline + Increased Depth + 4th Model: -3.9% - HARMFUL\n",
      "\n",
      "\n",
      "FULL RESULTS TABLE:\n",
      "                              config_name  accuracy  delta_pct  hc_accuracy  brier_score  auc_roc  n_games\n",
      "               4. Baseline + Vegas Spread  0.679688   1.171875     0.866667     0.221698 0.715286      256\n",
      "          3. Baseline + Momentum Features  0.675781   0.781250     0.923077     0.221430 0.723605      256\n",
      "         2. Baseline + Temporal Weighting  0.671875   0.390625     0.760000     0.221103 0.715042      256\n",
      "              1. BASELINE (Week 9 Legacy)  0.667969   0.000000     0.733333     0.221394 0.718345      256\n",
      "      8. FULL WEEK 10+ (All Enhancements)  0.652344  -1.562500     0.857143     0.219430 0.717121      256\n",
      "           5. Baseline + Injury Estimates  0.636719  -3.125000     0.823529     0.223551 0.701615      256\n",
      "            6. Baseline + Defensive Stats  0.628906  -3.906250     0.833333     0.223482 0.701278      256\n",
      "7. Baseline + Increased Depth + 4th Model  0.628906  -3.906250     0.807692     0.225246 0.699719      256\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "results_df = pd.DataFrame(ablation_results)\n",
    "\n",
    "# Calculate delta vs baseline\n",
    "baseline_acc = results_df.iloc[0]['accuracy']\n",
    "results_df['delta_vs_baseline'] = results_df['accuracy'] - baseline_acc\n",
    "results_df['delta_pct'] = results_df['delta_vs_baseline'] * 100\n",
    "\n",
    "# Sort by accuracy\n",
    "results_df = results_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"ABLATION STUDY RESULTS - 2024 HOLDOUT\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\n{'CONFIGURATION':<45} {'ACCURACY':<12} {'DELTA':<12} {'HC_ACC':<12} {'BRIER':<10}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    delta_str = f\"{row['delta_pct']:+.1f}%\"\n",
    "    hc_str = f\"{row['hc_accuracy']:.1%}\" if pd.notna(row['hc_accuracy']) else \"N/A\"\n",
    "    print(f\"{row['config_name']:<45} {row['accuracy']:>10.1%} {delta_str:>10} {hc_str:>10} {row['brier_score']:>9.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Identify best and worst\n",
    "best = results_df.iloc[0]\n",
    "worst = results_df.iloc[-1]\n",
    "\n",
    "print(f\"\\nüèÜ BEST: {best['config_name']}\")\n",
    "print(f\"   Accuracy: {best['accuracy']:.1%} ({best['delta_pct']:+.1f}% vs baseline)\")\n",
    "print(f\"   HC Accuracy: {best['hc_accuracy']:.1%}\" if pd.notna(best['hc_accuracy']) else \"\")\n",
    "\n",
    "print(f\"\\n‚ùå WORST: {worst['config_name']}\")\n",
    "print(f\"   Accuracy: {worst['accuracy']:.1%} ({worst['delta_pct']:+.1f}% vs baseline)\")\n",
    "\n",
    "# Feature impact summary\n",
    "print(f\"\\nüìä FEATURE IMPACT ANALYSIS:\")\n",
    "print(f\"   Baseline (Week 9 Legacy): {baseline_acc:.1%}\")\n",
    "\n",
    "for _, row in results_df[1:].iterrows():  # Skip baseline\n",
    "    impact = \"HELPFUL\" if row['delta_vs_baseline'] > 0.01 else \"HARMFUL\" if row['delta_vs_baseline'] < -0.01 else \"NEUTRAL\"\n",
    "    print(f\"   {row['config_name'][3:]}: {row['delta_pct']:+.1f}% - {impact}\")\n",
    "\n",
    "# Display full table\n",
    "print(\"\\n\\nFULL RESULTS TABLE:\")\n",
    "print(results_df[['config_name', 'accuracy', 'delta_pct', 'hc_accuracy', 'brier_score', 'auc_roc', 'n_games']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Results saved to: ablation_study_results.csv\n",
      "‚úÖ Postmortem report saved to: Week10_Enhancement_Postmortem.md\n",
      "\n",
      "======================================================================\n",
      "ABLATION STUDY COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "results_df.to_csv('ablation_study_results.csv', index=False)\n",
    "print(\"\\n‚úÖ Results saved to: ablation_study_results.csv\")\n",
    "\n",
    "# Create summary report\n",
    "with open('Week10_Enhancement_Postmortem.md', 'w') as f:\n",
    "    f.write(\"# Week 10+ Enhancement Postmortem: Ablation Study Results\\n\\n\")\n",
    "    f.write(f\"**Test Date**: {pd.Timestamp.now().strftime('%Y-%m-%d')}\\n\")\n",
    "    f.write(f\"**Holdout Dataset**: 2024 NFL Season (Weeks 1-18)\\n\")\n",
    "    f.write(f\"**Baseline**: Week 9 Legacy Model (60.8% expected)\\n\\n\")\n",
    "    \n",
    "    f.write(\"---\\n\\n\")\n",
    "    f.write(\"## Executive Summary\\n\\n\")\n",
    "    f.write(f\"- **Baseline Accuracy**: {baseline_acc:.1%}\\n\")\n",
    "    f.write(f\"- **Best Configuration**: {best['config_name']} ({best['accuracy']:.1%})\\n\")\n",
    "    f.write(f\"- **Worst Configuration**: {worst['config_name']} ({worst['accuracy']:.1%})\\n\")\n",
    "    f.write(f\"- **Full Week 10 Performance**: {results_df[results_df['config_name'].str.contains('FULL')].iloc[0]['accuracy']:.1%}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Detailed Results\\n\\n\")\n",
    "    f.write(\"| Configuration | Accuracy | Delta | HC Accuracy | Brier | AUC | Games |\\n\")\n",
    "    f.write(\"|---------------|----------|-------|-------------|-------|-----|-------|\\n\")\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        hc_str = f\"{row['hc_accuracy']:.1%}\" if pd.notna(row['hc_accuracy']) else \"N/A\"\n",
    "        f.write(f\"| {row['config_name']} | {row['accuracy']:.1%} | {row['delta_pct']:+.1f}% | {hc_str} | {row['brier_score']:.3f} | {row['auc_roc']:.3f} | {row['n_games']} |\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Feature Impact Summary\\n\\n\")\n",
    "    \n",
    "    for _, row in results_df[1:].iterrows():\n",
    "        impact = \"‚úÖ HELPFUL\" if row['delta_vs_baseline'] > 0.01 else \"‚ùå HARMFUL\" if row['delta_vs_baseline'] < -0.01 else \"‚ö™ NEUTRAL\"\n",
    "        f.write(f\"- **{row['config_name'][3:]}**: {row['delta_pct']:+.1f}% - {impact}\\n\")\n",
    "    \n",
    "    f.write(\"\\n## Recommendations\\n\\n\")\n",
    "    f.write(\"Based on ablation study results:\\n\\n\")\n",
    "    \n",
    "    helpful = results_df[results_df['delta_vs_baseline'] > 0.01]\n",
    "    harmful = results_df[results_df['delta_vs_baseline'] < -0.01]\n",
    "    \n",
    "    if len(helpful) > 1:  # Exclude baseline\n",
    "        f.write(\"### Keep These Features:\\n\")\n",
    "        for _, row in helpful[helpful['config_name'] != '1. BASELINE (Week 9 Legacy)'].iterrows():\n",
    "            f.write(f\"- {row['config_name'][3:]} ({row['delta_pct']:+.1f}%)\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    if len(harmful) > 0:\n",
    "        f.write(\"### Remove These Features:\\n\")\n",
    "        for _, row in harmful.iterrows():\n",
    "            f.write(f\"- {row['config_name'][3:]} ({row['delta_pct']:+.1f}%)\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"### Next Steps:\\n\")\n",
    "    f.write(\"1. Revert to baseline for Week 16\\n\")\n",
    "    f.write(\"2. Add ONLY validated helpful features one at a time\\n\")\n",
    "    f.write(\"3. Test each on 2024 holdout before deploying to 2025\\n\")\n",
    "    f.write(\"4. Build validation framework to prevent future regressions\\n\")\n",
    "\n",
    "print(\"‚úÖ Postmortem report saved to: Week10_Enhancement_Postmortem.md\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION STUDY COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation 3: Validate Momentum on 2023 Data\n",
    "\n",
    "**Question**: Does momentum's +0.8% improvement and 92.3% HC accuracy generalize to 2023, or was it 2024-specific?\n",
    "\n",
    "**Context**: Ablation study on 2024 showed:\n",
    "- Momentum Features: 67.6% accuracy (+0.8% vs baseline)\n",
    "- HC Accuracy: 92.3% (best of all tests!)\n",
    "- BUT: Your Week 10-14 production showed only 55.0% HC accuracy\n",
    "\n",
    "**Risk**: Momentum may be overfitted to 2024 season characteristics\n",
    "\n",
    "**Hypothesis**: If momentum is truly predictive, it should also improve performance on 2023 data\n",
    "\n",
    "**Test**: Re-run Test #3 (Momentum Features) with TEST_YEAR = 2023\n",
    "\n",
    "**Expected Outcomes**:\n",
    "- If momentum helps on 2023 → Deploy to Week 16 with confidence ✅\n",
    "- If momentum hurts on 2023 → Year-specific overfitting, DO NOT deploy ❌\n",
    "- If momentum neutral on 2023 → Proceed cautiously, test on 2022 as well ⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cached Data\n",
    "\n",
    "Reuse data from ablation study to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from ablation study cache\n",
    "import os\n",
    "\n",
    "cache_dir = 'ablation_cache'\n",
    "if os.path.exists(f'{cache_dir}/pbp_data.csv'):\n",
    "    print(\"Loading cached data from ablation study...\")\n",
    "    pbp_data = pd.read_csv(f'{cache_dir}/pbp_data.csv')\n",
    "    weekly_data = pd.read_csv(f'{cache_dir}/weekly_data.csv')\n",
    "    schedule_data = pd.read_csv(f'{cache_dir}/schedule_data.csv')\n",
    "    print(f\"✅ Loaded {len(pbp_data):,} play-by-play rows\")\n",
    "    print(f\"✅ Loaded {len(weekly_data):,} weekly stat rows\")\n",
    "    print(f\"✅ Loaded {len(schedule_data):,} games\")\n",
    "else:\n",
    "    print(\"❌ Cache not found. Run debug_enhanced_model.ipynb first to generate cache.\")\n",
    "    raise FileNotFoundError(\"Ablation study cache required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Momentum Feature Engineering\n",
    "\n",
    "Extract exact implementation from ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_momentum_features(features, weekly_data, team, season, week):\n",
    "    \"\"\"\n",
    "    Add momentum features based on last 3 games.\n",
    "    \n",
    "    Implementation from ablation study:\n",
    "    - momentum_last3: Approximate win rate from fantasy points scored\n",
    "    - Formula: last_3_weeks.fantasy_points.mean() / 30.0\n",
    "    \"\"\"\n",
    "    team_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    if len(team_stats) >= 3:\n",
    "        last_3_weeks = sorted(team_stats['week'].unique())[-3:]\n",
    "        last_3_stats = team_stats[team_stats['week'].isin(last_3_weeks)]\n",
    "        # Approximate win rate from points scored vs allowed\n",
    "        features['momentum_last3'] = last_3_stats.groupby('week')['fantasy_points'].sum().mean() / 30.0\n",
    "    else:\n",
    "        features['momentum_last3'] = 0.5  # Neutral for early season\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_game_features_with_momentum(home_team, away_team, season, week, weekly_data):\n",
    "    \"\"\"\n",
    "    Create game features including momentum.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Get team stats\n",
    "    home_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == home_team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    away_stats = weekly_data[\n",
    "        (weekly_data['recent_team'] == away_team) &\n",
    "        (weekly_data['season'] == season) &\n",
    "        (weekly_data['week'] < week)\n",
    "    ]\n",
    "    \n",
    "    # Basic features (simplified version)\n",
    "    for prefix, stats in [('home', home_stats), ('away', away_stats)]:\n",
    "        if len(stats) > 0:\n",
    "            features[f'{prefix}_passing_ypg'] = stats['passing_yards'].sum() / len(stats['week'].unique())\n",
    "            features[f'{prefix}_rushing_ypg'] = stats['rushing_yards'].sum() / len(stats['week'].unique())\n",
    "            features[f'{prefix}_total_ypg'] = features[f'{prefix}_passing_ypg'] + features[f'{prefix}_rushing_ypg']\n",
    "        else:\n",
    "            features[f'{prefix}_passing_ypg'] = 0\n",
    "            features[f'{prefix}_rushing_ypg'] = 0\n",
    "            features[f'{prefix}_total_ypg'] = 0\n",
    "    \n",
    "    # Add momentum features\n",
    "    home_features = {}\n",
    "    away_features = {}\n",
    "    add_momentum_features(home_features, weekly_data, home_team, season, week)\n",
    "    add_momentum_features(away_features, weekly_data, away_team, season, week)\n",
    "    \n",
    "    features['home_momentum_last3'] = home_features.get('momentum_last3', 0.5)\n",
    "    features['away_momentum_last3'] = away_features.get('momentum_last3', 0.5)\n",
    "    features['momentum_advantage'] = features['home_momentum_last3'] - features['away_momentum_last3']\n",
    "    \n",
    "    # Contextual\n",
    "    features['season'] = season\n",
    "    features['week'] = week\n",
    "    features['is_playoff'] = 1 if week >= 18 else 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"✅ Momentum feature functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Datasets for 2023 and 2024 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_momentum_test(weekly_data, schedule_data, test_year):\n",
    "    \"\"\"\n",
    "    Build dataset with and without momentum features.\n",
    "    Train on all data before test_year, test on test_year.\n",
    "    \"\"\"\n",
    "    print(f\"\\nBuilding datasets for TEST_YEAR = {test_year}...\")\n",
    "    \n",
    "    games = []\n",
    "    \n",
    "    # Use all seasons from 2015 to test_year\n",
    "    for season in range(2015, test_year + 1):\n",
    "        season_schedule = schedule_data[schedule_data['season'] == season]\n",
    "        \n",
    "        for week in range(1, 19):\n",
    "            week_games = season_schedule[season_schedule['week'] == week]\n",
    "            \n",
    "            for _, game in week_games.iterrows():\n",
    "                home_team = game['home_team']\n",
    "                away_team = game['away_team']\n",
    "                \n",
    "                if pd.isna(home_team) or pd.isna(away_team):\n",
    "                    continue\n",
    "                \n",
    "                # Create features WITH momentum\n",
    "                features_with = create_game_features_with_momentum(\n",
    "                    home_team, away_team, season, week, weekly_data\n",
    "                )\n",
    "                \n",
    "                # Outcome\n",
    "                home_score = game.get('home_score', 0)\n",
    "                away_score = game.get('away_score', 0)\n",
    "                \n",
    "                if pd.notna(home_score) and pd.notna(away_score):\n",
    "                    features_with['home_win'] = 1 if home_score > away_score else 0\n",
    "                    features_with['season'] = season\n",
    "                    features_with['week'] = week\n",
    "                    games.append(features_with)\n",
    "    \n",
    "    df_with_momentum = pd.DataFrame(games)\n",
    "    \n",
    "    # Create baseline version (remove momentum columns)\n",
    "    df_baseline = df_with_momentum.drop(columns=['home_momentum_last3', 'away_momentum_last3', 'momentum_advantage'], errors='ignore')\n",
    "    \n",
    "    print(f\"✅ Built {len(df_with_momentum)} games\")\n",
    "    print(f\"   Baseline features: {len(df_baseline.columns) - 3}\")\n",
    "    print(f\"   With momentum features: {len(df_with_momentum.columns) - 3}\")\n",
    "    \n",
    "    return df_baseline, df_with_momentum\n",
    "\n",
    "# Build for 2023\n",
    "df_2023_baseline, df_2023_momentum = build_dataset_for_momentum_test(weekly_data, schedule_data, 2023)\n",
    "\n",
    "# Build for 2024 (for comparison)\n",
    "df_2024_baseline, df_2024_momentum = build_dataset_for_momentum_test(weekly_data, schedule_data, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Momentum on 2023 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_momentum_on_year(df_baseline, df_momentum, test_year):\n",
    "    \"\"\"\n",
    "    Walk-forward validation on test_year.\n",
    "    Compare baseline vs momentum features.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTING MOMENTUM ON {test_year} DATA\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    train_end_year = test_year - 1\n",
    "    \n",
    "    # Split train/test\n",
    "    train_baseline = df_baseline[df_baseline['season'] < test_year]\n",
    "    test_baseline = df_baseline[df_baseline['season'] == test_year]\n",
    "    \n",
    "    train_momentum = df_momentum[df_momentum['season'] < test_year]\n",
    "    test_momentum = df_momentum[df_momentum['season'] == test_year]\n",
    "    \n",
    "    print(f\"\\nTraining data: 2015-{train_end_year} ({len(train_baseline)} games)\")\n",
    "    print(f\"Testing data: {test_year} ({len(test_baseline)} games)\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for config_name, train_df, test_df in [\n",
    "        (\"BASELINE (No Momentum)\", train_baseline, test_baseline),\n",
    "        (\"WITH MOMENTUM FEATURES\", train_momentum, test_momentum)\n",
    "    ]:\n",
    "        print(f\"\\n{'-'*80}\")\n",
    "        print(f\"Testing: {config_name}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        \n",
    "        # Prepare features\n",
    "        X_train = train_df.drop(columns=['home_win', 'season', 'week'])\n",
    "        y_train = train_df['home_win']\n",
    "        X_test = test_df.drop(columns=['home_win', 'season', 'week'])\n",
    "        y_test = test_df['home_win']\n",
    "        \n",
    "        # Handle missing values\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "        \n",
    "        # Feature selection (RFE)\n",
    "        rf_selector = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        rfe = RFECV(rf_selector, min_features_to_select=10, cv=3, scoring='accuracy')\n",
    "        rfe.fit(X_train, y_train)\n",
    "        \n",
    "        X_train_selected = rfe.transform(X_train)\n",
    "        X_test_selected = rfe.transform(X_test)\n",
    "        \n",
    "        selected_features = X_train.columns[rfe.support_].tolist()\n",
    "        print(f\"   Selected {len(selected_features)} features via RFE\")\n",
    "        if 'momentum_advantage' in selected_features or 'home_momentum_last3' in selected_features:\n",
    "            print(f\"   ✅ RFE selected momentum features (model considers them useful)\")\n",
    "        elif config_name == \"WITH MOMENTUM FEATURES\":\n",
    "            print(f\"   ⚠️ RFE did NOT select momentum features (model doesn't find them useful)\")\n",
    "        \n",
    "        # Train ensemble (3-model like baseline)\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42)\n",
    "        lr = LogisticRegression(C=1.0, max_iter=1000, random_state=42)\n",
    "        xgb = XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=200, random_state=42, eval_metric='logloss')\n",
    "        \n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=[('rf', rf), ('lr', lr), ('xgb', xgb)],\n",
    "            voting='soft'\n",
    "        )\n",
    "        \n",
    "        calibrated_model = CalibratedClassifierCV(ensemble, method='isotonic', cv=3)\n",
    "        calibrated_model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = calibrated_model.predict(X_test_selected)\n",
    "        y_proba = calibrated_model.predict_proba(X_test_selected)[:, 1]\n",
    "        \n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # High-confidence accuracy\n",
    "        hc_mask = (y_proba >= 0.70) | (y_proba <= 0.30)\n",
    "        if hc_mask.sum() > 0:\n",
    "            hc_accuracy = accuracy_score(y_test[hc_mask], y_pred[hc_mask])\n",
    "        else:\n",
    "            hc_accuracy = None\n",
    "        \n",
    "        brier = brier_score_loss(y_test, y_proba)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        results[config_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'hc_accuracy': hc_accuracy,\n",
    "            'brier_score': brier,\n",
    "            'auc_roc': auc,\n",
    "            'n_games': len(y_test),\n",
    "            'n_hc_games': hc_mask.sum()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n   Results:\")\n",
    "        print(f\"   Overall Accuracy: {accuracy:.1%} ({int(accuracy * len(y_test))}/{len(y_test)} games)\")\n",
    "        if hc_accuracy is not None:\n",
    "            print(f\"   HC Accuracy (≥70%): {hc_accuracy:.1%} ({hc_mask.sum()} games)\")\n",
    "        print(f\"   Brier Score: {brier:.3f}\")\n",
    "        print(f\"   AUC-ROC: {auc:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test on 2023\n",
    "results_2023 = test_momentum_on_year(df_2023_baseline, df_2023_momentum, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Momentum on 2024 Data (For Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 2024 for comparison\n",
    "results_2024 = test_momentum_on_year(df_2024_baseline, df_2024_momentum, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results Across Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MOMENTUM FEATURE VALIDATION - CROSS-YEAR COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for year, results in [(2023, results_2023), (2024, results_2024)]:\n",
    "    baseline = results['BASELINE (No Momentum)']\n",
    "    momentum = results['WITH MOMENTUM FEATURES']\n",
    "    \n",
    "    delta = momentum['accuracy'] - baseline['accuracy']\n",
    "    hc_delta = (momentum['hc_accuracy'] - baseline['hc_accuracy']) if (momentum['hc_accuracy'] and baseline['hc_accuracy']) else None\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Year': year,\n",
    "        'Baseline Acc': f\"{baseline['accuracy']:.1%}\",\n",
    "        'Momentum Acc': f\"{momentum['accuracy']:.1%}\",\n",
    "        'Delta': f\"{delta:+.1%}\",\n",
    "        'Baseline HC': f\"{baseline['hc_accuracy']:.1%}\" if baseline['hc_accuracy'] else 'N/A',\n",
    "        'Momentum HC': f\"{momentum['hc_accuracy']:.1%}\" if momentum['hc_accuracy'] else 'N/A',\n",
    "        'HC Delta': f\"{hc_delta:+.1%}\" if hc_delta else 'N/A'\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION & RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate average delta\n",
    "delta_2023 = results_2023['WITH MOMENTUM FEATURES']['accuracy'] - results_2023['BASELINE (No Momentum)']['accuracy']\n",
    "delta_2024 = results_2024['WITH MOMENTUM FEATURES']['accuracy'] - results_2024['BASELINE (No Momentum)']['accuracy']\n",
    "avg_delta = (delta_2023 + delta_2024) / 2\n",
    "\n",
    "print(f\"\\nAverage Delta Across Both Years: {avg_delta:+.1%}\")\n",
    "\n",
    "if delta_2023 > 0 and delta_2024 > 0:\n",
    "    print(\"\\n✅ RECOMMENDATION: DEPLOY MOMENTUM FEATURES\")\n",
    "    print(\"   Momentum consistently improves accuracy on both 2023 and 2024\")\n",
    "    print(\"   This suggests the feature generalizes well and is not year-specific\")\n",
    "    print(f\"   Expected improvement: {avg_delta:+.1%}\")\n",
    "elif delta_2023 < -0.01 or delta_2024 < -0.01:\n",
    "    print(\"\\n❌ RECOMMENDATION: DO NOT DEPLOY MOMENTUM FEATURES\")\n",
    "    print(\"   Momentum hurts performance on at least one test year\")\n",
    "    print(\"   Risk of year-specific overfitting or inconsistent signal\")\n",
    "    print(\"   Stick with baseline model\")\n",
    "else:\n",
    "    print(\"\\n⚠️ RECOMMENDATION: PROCEED WITH CAUTION\")\n",
    "    print(\"   Momentum shows mixed results or minimal impact\")\n",
    "    print(\"   Consider testing on 2022 data for additional validation\")\n",
    "    print(\"   May deploy if HC accuracy consistently improved\")\n",
    "\n",
    "# Check HC consistency\n",
    "hc_2023 = results_2023['WITH MOMENTUM FEATURES'].get('hc_accuracy')\n",
    "hc_2024 = results_2024['WITH MOMENTUM FEATURES'].get('hc_accuracy')\n",
    "\n",
    "if hc_2023 and hc_2024:\n",
    "    if hc_2023 >= 0.70 and hc_2024 >= 0.70:\n",
    "        print(f\"\\n✅ HIGH-CONFIDENCE PICKS: Consistently strong (2023: {hc_2023:.1%}, 2024: {hc_2024:.1%})\")\n",
    "    elif hc_2023 < 0.65 or hc_2024 < 0.65:\n",
    "        print(f\"\\n❌ HIGH-CONFIDENCE PICKS: Inconsistent or weak (2023: {hc_2023:.1%}, 2024: {hc_2024:.1%})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison\n",
    "comparison_df.to_csv('investigation_3_momentum_validation_results.csv', index=False)\n",
    "print(\"\\n✅ Saved results to investigation_3_momentum_validation_results.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INVESTIGATION 3 COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Review comparison table above\")\n",
    "print(\"2. If momentum helps consistently → Proceed to deploy in Week 16\")\n",
    "print(\"3. If momentum inconsistent → Run investigation_4 to test feature pairs\")\n",
    "print(\"4. Document findings in feature_experiment_log.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
